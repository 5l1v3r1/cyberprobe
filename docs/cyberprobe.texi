\input texinfo   @c -*-texinfo-*-

@comment $Id@w{$}
@comment %**start of header
@setfilename cyberprobe.info
@include version.texi
@include paths.texi

@settitle Cyberprobe @value{VERSION}
@syncodeindex pg cp
@paragraphindent 0
@comment %**end of header

@copying
This manual is for Cyberprobe (version @value{VERSION}, @value{UPDATED}),
which is an example in the Texinfo documentation.

Copyright @copyright{} 2013-2014 Cyber MacGeddon

@quotation
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.3 or
any later version published by the Free Software Foundation; with no
Invariant Sections, with no Front-Cover Texts, and with no Back-Cover
Texts.  A copy of the license is included in the section entitled
``GNU Free Documentation License''.
@end quotation
@end copying

@dircategory Texinfo documentation system
@direntry
* overview: (overview)Overview.
@end direntry

@titlepage
@title Cyberprobe
@subtitle for version @value{VERSION}, @value{UPDATED}
@author Cyber MacGeddon (@email{cyberprobe@@trustnetworks.com})
@page
@vskip 0pt plus 1filll
@insertcopying
@end titlepage

@c @ifnottex
@node Top
@top Cyberprobe

This is the manual for Cyberprobe (version @value{VERSION}, @value{UPDATED}).

@image{cyberprobe-overview,125mm,,png}

Cyberprobe is a distrbuted architecture for real-time monitoring of networks
against attack. This has applications in network monitoring,
intrusion detection, forensic analysis, and as a defensive platform during
an attack.

The software consists of a number of components, including:

@itemize @bullet

@item
a probe, which collects data packets and forwards it over a network in
standard streaming protocols.

@item
a monitor, which receives the streamed packets, decodes the protocols, and
interprets the information.

@item
a set of subscribers which can be used to do things with the captured data
e.g. store to ElasticSearch, BigQuery or Gaffer.

@end itemize

These components can be used together or separately. For a simple
configuration, they can be run on the same host, for more complex
environments, a number of probes can feed a single monitor. For more detail,
and to see where we are going, read the @ref{Architecture} page.

@quotation Note
FIXME: Architecture diagram needs an update.
@end quotation

@c @end ifnottex

@menu
* Overview::
* Obtaining the software::
* Quick start tutorial::
* Running cyberprobe/cybermon::
* The pub/sub infrastructure::
* A containerised processing system::
* Endace DAG::
* Reference::
* Architecture::
* GNU Free Documentation License::
* Index::
@end menu

@comment ----------------------------------------------------------------------

@node Overview
@chapter Overview

@cindex Overview of Cyberprobe
@heading Summary

Cyberprobe is a distrbuted architecture for real-time monitoring of networks
against attack. The software consists of a number of components, including:

@itemize @bullet

@item
a probe, which collects data packets and forwards it over a network in
a streaming protocol.

@item
a monitor, which receives the streamed packets, decodes the protocols, and
interprets the information.

@item
a set of subscribers which can be used to do things with the captured data
e.g. store to ElasticSearch, BigQuery or Gaffer.

@end itemize

@cindex @command{cyberprobe}, features
@cindex Features, of @command{cyberprobe}

These components can be used together or separately. For a simple
configuration, they can be run on the same host, for more complex
environments, a number of probes can feed a single monitor. For more detail,
and to see where we are going, read the @ref{Architecture} page.

The probe, @command{cyberprobe} has the following features:

@itemize @bullet

@item
The probe can be tasked to collect packets from an interface and forward any
which match a configurable address list.

@item
The probe can be configured to receive Snort alerts. In this configuration,
when an alert is received from Snort, the IP source address associated with
the alert is dynamically targeted for a period of time. In such a
configuration, the system will collect data from any network actor who
triggers a snort rule and is thus identified as a potential attacker.

@item
The probe can optionally run a management interface which allows remote
interrogation of the state, and alteration of the configuration. This
allows dynamic alteration of the targeting map, and integration with other
systems.

@item
The probe can be configured to deliver on one of two standard stream
protocols.

@end itemize

@cindex @command{cybermon}, features
@cindex Features, of @command{cybermon}

The monitor tool, @command{cybermon} has the following features:

@itemize @bullet

@item
Collects packets delivered in stream protocols.

@item
Decodes packet protocols in and raises events in near-real-time.

@item
Decoded information is made available to user-configurable logic to define
how the decoded data is handled. A simple configuration language is used
(LUA) and example configurations are provided to monitor data volumes,
display data hexdumps, or stash the data in files.

@item
Packet forgery techniques are included, which allow resetting TCP
connections, and forging DNS responses. This can be invoked from your LUA in
order to fight back against attacks on your network.

@item
Supports IP, TCP, UDP, ICMP, HTTP and DNS protocols, currently.

@end itemize

The code is targeted at the Linux platform, although it is generic enough to
be applicable to other UN*X-like platforms.

The easiest way to learn about the software is to follow our Quick Start
tutorial.

@cindex Release history
@cindex Version history
@heading Revision history

Cyberprobe releases:

@table @code

@item 1.10.0
Add RabbitMQ / AMQP 0.9.1 support for cybermon and subscribers.

@item 1.8.4
Endace DAG package support added.

@item 1.7.0
Gaffer subscriber brought up-to-date with Gaffer 1.0 API.  GeoIP and
IOC processor added to the subscriber model.  Some unmaintained Lua code
deprecated, as the subscriber model takes care of the functionality.

@item 1.6.8
Numerous fixes. UUID generation uses a good seed.  ElasticSearch loading
fixed, Mac compilation fixed.

@item 1.6.0
Changed ETSI sender so that packet streams are multiplexed over multiple
TCP streams.

@item 1.5.1
Unbounded queue internal to cybermon has a queue limit, to prevent unbounded
growth.

@item 1.5.0
Timestamp information at the time of packet capture in cyberprobe is now
consistently passed through to cybermon and the Lua functions.  The Lua API
has undergone significant change as a result of passing through timing
information.

@item 1.0
Lua invocation mechanism has been replaced by a thread-safe queue function.

@item 0.99
Elliptic curve support in TLS, if supported in OpenSSL.

@item 0.95
Fixed cyberprobe to cybermon transport dropout.

@item 0.94
Reworked the JSON model, to make different protocol attributes more clearly
defined.

@item 0.93
DNS over TCP, and simple port-based detection for IMAP, SMTP auth, SIP.

@item 0.92
Changed DNS and ICMP type field in JSON, DNS class and type are presented
as strings.

@item 0.91
Redis integration using @code{redis.lua} configuration file.

@item 0.90
NTP handling, DNS output format changed, robustness fixes in TCP handling.

@item 0.83
Point release, minor fixes.

@item 0.80
Added optional TLS support for packet streams to cyberprobe and cybermon.
This change refactors the cybermon command line interface.  See documentation
for new command line options.

@item 0.79
Socket closure fix.

@item 0.76
Make UUIDs unique.

@item 0.74
Cassanda subscriber support.

@item 0.71
Fixes.

@item 0.70
Added ZeroMQ pub/sub support, with subscribers for ElasticSearch, Gaffer,
Google BigQuery.

@item 0.63
ElasticSearch integration brought up to latest ES verison.
Cybermon Gaffer integration work completed to point of release.

@item 0.62
Source-code updated to work with latest dependencies, operating systems and
compiler versions.  Early Gaffer integration.

@item 0.61
Fixed HTTP crashing problem in cybermon.

@item 0.60
IP address matching now permits specification of a mask.
Documentation improved, regression suite added, a few unit tests starting to
form.  

@item 0.55
Packages released for Debian, Fedora and Centos, documentation
re-worked into info and man formats.

@item 0.50
ElasticSearch integration improved to get a much tighter integration with
Kibana for a network dashboard. Also bug-fixes for memory management / lock
problems.

@item 0.40
Now includes prototype STIX support: A TAXII server allows distrubution of
threat information, and a TAXII client can read indicator information and
store in a way that cybermon can use.

@item 0.30
The build process now uses the GNU toolset. It detects the LUA interface and
can compile against LUA 5.1 and 5.2. Successfully compiled on a MacBook!

@item 0.25
Added SMTP and FTP capability. Also added a primitive mechanism to visualise
network observations.

@item 0.20
HTTP and DNS protocol capability. TCP reset and DNS packet forgery
added. Major overhaul of the LUA language interface.

@item 0.12
Cybermon utility is configurable using LUA.

@item 0.11
Added basic cybermon utility.

@item 0.10
Added management interface.

@item 0.9
First release on SourceForge.

@end table

@comment ----------------------------------------------------------------------

@node Obtaining the software
@chapter Obtaining the software

@heading Deployment using containers

Deploying containers is by far the easiest way to get the software running.
It is possible to deploy a complete software stack for data capture and
analysis using Docker containers which requires the minimal amount of
software installation.
See @ref{A containerised processing system}.

@heading Debian / Ubuntu repository

We use GoCD to build the software, and regularly release packages
in DEB and RPM form.  Installing from the repository is the easiest way to
install if you're not using containers.

In order to install, you need to add our signing key to your system:

@example
  wget -q -O- http://download.trustnetworks.com/trust-networks.asc | \
    apt-key add -
@end example

We use this signing key:
@example
@include signing.texi
@end example

Once done you then add our repository to @file{/etc/apt/sources.list}.

For Debian Stretch, add:
@example
deb http://download.trustnetworks.com/debian stretch main
@end example

For Debian Jessie, add:
@example
deb http://download.trustnetworks.com/debian jessie main
@end example

For Debian Wheezy, add:
@example
deb http://download.trustnetworks.com/debian wheezy main
@end example

For Ubuntu Artful, add:
@example
deb http://download.trustnetworks.com/ubuntu artful main
@end example

For Ubuntu Zesty, add:
@example
deb http://download.trustnetworks.com/ubuntu zesty main
@end example

Once added, the cyberprobe installation proceeds thus:

@example
apt-get update
apt-get install cyberprobe
@end example

@heading Centos / Fedora

To install using Yum or DNF, create file
@file{/etc/yum.repos.d/trust-networks.repo}:

@example
[trustnetworks]
name=Trust Networks
baseurl=http://download.trustnetworks.com/fedora/$releasever/$basearch/
gpgcheck=1
enabled=1
gpgkey=http://download.trustnetworks.com/trust-networks.asc
@end example

and then:

@example
dnf install cyberprobe
@end example

Or, for Centos 7:

@example
yum install cyberprobe
@end example

We use this signing key:
@example
@include signing.texi
@end example

@heading Download packages

You can download packages manually; packages are currently available for
Fedora, CentOS, Debian and Ubuntu.  Downloads are available on the project
page at
@url{http://github.com/cybermaggedon/cyberprobe/releases}.

Fedora packages are installed using @code{dnf}:

@example
sudo dnf install <package>
@end example

Debian and Ubuntu packages are installed using @code{dpkg}:

@example
sudo dpkg -i <package>
@end example

If there are dependency errors e.g. because you don't have some dependencies
installed, you can install them thus:

@example
sudo apt-get install -f
@end example

@heading Install from source

Note: on many platforms, installing a package just adds the "run time" part
of the code. In order to be able to compile code against the run time, you
need to install a separate "developers kit" package. On Fedora, for
instance, both @code{libpcap} and @code{libpcap-devel} are needed in order to
be able to build this code from source.

Note also that @code{lua} packages can be a little strange: sometimes the
package will exist in your distribution, at other times you need to install a
utility called @code{luarocks} to install the package.

Source downloads are available on the project page at
@url{http://github.com/cybermaggedon/cyberprobe/releases},
look for the @file{.tar.gz} file.

These files can be unwrapped, then configured:

@example
tar xvfz cyberprobe-X.Y.tar.gz
cd cyberprobe-X.Y
./configure
make
sudo make install
@end example

@file{README.linux} provides some hints for Linux users.
If installing on MacOS, read @file{README.mac}.

@cindex Checkout from @command{git} repository
@cindex @command{git} repository
@heading Installing from git

To checkout the latest code using git:

@example
git clone http://git.code.sf.net/p/cyberprobe/code cyberprobe
@end example

To build, use:

@example
autoreconf -fi
./configure
make
sudo make install
@end example

Powered by Github, project page is at
@url{http://cyberprobe.trustnetworks.com}.

@cindex Docker
@cindex Containers
@cindex Cyberprobe, docker repository
@cindex @command{cyberprobe}, docker repository
@cindex @command{cybermon}, docker repository
@heading Docker repository

There are two Docker repositories containing the Cyberprobe distribution.
See @url{http://hub.docker.com/r/cybermaggedon/cyberprobe}.

@itemize

@item
@code{docker.io/cybermaggedon/cyberprobe}

@item
@code{docker.io/cybermaggedon/cybermon}

@end itemize

The only difference is the default command which is executed on running
the container.  Here are some container invocations you may find useful:

@itemize

@item
Run @command{cyberprobe}.  You will need to create a configuration file
and map it in to the container.
@example
sudo docker -it --rm -v /etc/cyberprobe:/etc/cyberprobe_host \
  docker.io/cybermaggedon/cyberprobe \
  cyberprobe /etc/cyberprobe_host/cyberprobe.fg
@end example

@item
Run @command{cybermon}.  The @command{cybermon} container exposes port
9000.
@example
sudo docker -it --rm -p 9000:9000 -v \
  --net=host --privileged --cap-add=NET_ADMIN \
  docker.io/cybermaggedon/cybermon \
  cybermon -p 9000 -c /etc/cyberprobe/amqp-topic.lua
@end example

@item
Run @command{cybermon-cassandra}.  You need to know the IP address
of the host side of the Docker bridge network, and provide addresses
of the Cassandra servers.
@example
sudo docker -it --rm -v \
  docker.io/cybermaggedon/cybermon \
  cybermon-cassandra cyberprobe \
  10.142.146.6,10.142.146.8
@end example

@end itemize

Running cyberprobe in a container makes the deployment easier, but it needs
to run with elevated privileges in order to sniff the network, which reduces
some of the advantages of running it in a container.

@heading Dependencies

The code doesn't have many dependencies. Exotic dependencies are:

@cindex dependencies
@cindex Build dependencies
@cindex Boost
@cindex Lua
@cindex @code{libpcap}
@cindex @code{expat}
@cindex @code{tcpdump}
@cindex @code{telnet}
@cindex @code{luafilesystem}
@cindex @code{luajson}
@cindex @code{libtaxii}
@cindex @code{stix}
@cindex @code{lua-md5}
@cindex @code{ncurses}
@cindex @code{readline}

@itemize

@item
Boost regex.

@item
Boost shared pointer.

@item
LUA - 5.1 or later.

@item
GCC C++ compiler and development support.

@item
@code{libpcap}.

@item
Expat (XML parser).

@item
@code{tcpdump} - not needed to build the software, but we use it in the
tutorial.

@item
@code{telnet} - not needed to build the software, but we use it in the
tutorial.

@item
@code{luafilesystem}, if using certain Lua configuration files.

@item
@code{luajson}, if using certain Lua configuration files.

@item
@code{lua-md5}, for MD5 hashing payloads.

@item
@code{ncurses}, needed for the command line admin utility.

@item
@code{readline}, needed for the command line admin utility.

@item
For STIX support, @code{libtaxii} and @code{stix} are Python modules
made available at @url{http://mitre.org} which can be downloaded using
@code{pip}.

@end itemize

@comment ----------------------------------------------------------------------

@node Quick start tutorial
@chapter Quick start tutorial
@cindex Getting started


@menu
* Preparation::
* Using @command{cyberprobe}::
* Management interface::
* Integration with @command{snort}::
* Using @command{cybermon}::
* Writing your own configuration file::
* Visualisation::
* Threat indicators using STIX::
@end menu

@comment ----------------------------------------------------------------------

@node Preparation
@section Preparation

@cindex Building
@cindex Downloading
@cindex Compilation
@cindex Packages
@cindex Installation
@heading Build software

For installation, see @ref{Obtaining the software}.
There's a fair amount of development taking place in the git repository, so
you probably want to get the a package, or use the latest release on the
downloads page (@url{http://github.com/cybermaggedon/cyberprobe/releases}).

@cindex Executables
@cindex Build targets

The compilation process compiles the following commands:

@table @command

@cindex @command{cyberprobe}
@item cyberprobe
Packet capture.

@cindex @command{cybermon}
@item cybermon
Data analyser, analyses the data streams and reports events.

@cindex @command{etsi-rcvr}
@item etsi-rcvr
Test decoder for ETSI format data.

@cindex @command{cyberprobe-cli}
@item cyberprobe-cli
Cyberprobe control command-line client.

@cindex @command{cybermon-bigquery}
@item cybermon-bigquery
Pub/sub subscriber, delivers events to Google Bigquery.

@cindex @command{cybermon-cassandra}
@item cybermon-cassandra
Pub/sub subscriber, delivers events to Cassandra.

@cindex @command{cybermon-elasticsearch}
@item cybermon-elasticsearch
Pub/sub subscriber, delivers events to ElasticSearch.

@cindex @command{cybermon-gaffer}
@item cybermon-gaffer
Pub/sub subscriber, delivers events to Gaffer.

@cindex @command{cybermon-geoip}
@item cybermon-geoip
Pub/sub subscriber, uses GeoIP to add location information to events, and
then republishes them.

@cindex @command{cybermon-detector}
@item cybermon-detector
Pub/sub subscriber, looks for matches for STIX IOCs, adds IOC information
to events, and then republishes them.

@cindex @command{cybermon-dump}
@item cybermon-dump
Pub/sub subscriber, dumps out raw JSON messages.

@cindex @command{cybermon-alert}
@item cybermon-dump
Pub/sub subscriber, alerts on matching IOCs.

@end table

@cindex Discussion forums

If it installs / builds without errors, then it's time to start something up. 
If you have problems you can't resolve raise an issue at
(@url{https://github.com/cybermaggedon/cyberprobe/issues}).

@cindex Network parameters
@heading Establish network parameters

The simplest way to use cyberprobe is to use it on a Linux workstation, or
in a virtual machine.  Maybe you're using a Linux desktop now now?  If so,
you could use it to capture all the data going to/from the internet. This
will be a static configuration in order to keep things simple. We'll do
dynamic tracking later.

In the next few steps, you'll use @command{cyberprobe} to capture some data,
on your workstation, and stream it to @command{etsi-rcvr} so that you know it's
working. But first, you'll need to collect some information about your
configuration.

@cindex @command{ifconfig}

You need to know the name of the network interface you are using. The
command @command{/sbin/ifconfig} will show you all the network interfaces
your machine knows about. e.g.

@example
lo: flags=73<UP,LOOPBACK,RUNNING>  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        inet6 ::1  prefixlen 128  scopeid 0x10
        [etc.]

eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500
        inet 192.168.1.80  netmask 255.255.255.0
        inet6 fe80::a60:6eff:fe81:7a75  prefixlen 64
        [etc.]
@end example

The lo interface is a loopback interface, and isn't really on the network,
so ignore that. It's an interface that gets packets going to
@code{127.0.0.1} and makes sure they end up handled by your
workstation. Your interface is quite likely to be called something like
eth0. The other thing you need to know is the IP address of your
workstation. The IP address is associated with an interface, so in the above
example, I can see I have an IP address @code{192.168.1.80}.

Note: on some networks (like mine) the IP address is allocated
dynamically. In my case, the IP address is allocated by the broadband
router. If things aren't working as you expect, you should check your IP
address to check your workstation hasn't been allocated a new, different
address. In my case, I can tell the broadband router to permanently allocate
a particular IP address to this workstation, so that it won't change.

@comment ----------------------------------------------------------------------

@node Using @command{cyberprobe}
@section Using @command{cyberprobe}
@cindex @command{cyberprobe}
@cindex @command{cyberprobe} configuration

@heading Starting cyberprobe with a configuration file

The source code contains a file @file{config.xml} which is a good template
for any configuration you're going to build. However, for the purpose of
this discussion, let's start from scratch. In order to do anything useful,
there are three essential elements to a cyberprobe configuration file:
interfaces, targets and endpoints. The system won't do anything useful
without those three configuration elements defined. Let's start with a very
simple configuration.

Using your favourite text editor, create a text file, say @file{c.xml} with the
following contents:

@example
<?xml version="1.0" encoding="ISO-8859-1"?>

<configuration>

  <interfaces>
    <interface name="eth0"/>
  </interfaces>

  <targets>
  </targets>

  <endpoints>
  </endpoints>

</configuration>
@end example

Note: You should replace the @code{eth0} string with the name of your
network interface. Remember? We discovered that when playing with the
@command{ifconfig} command.

@cindex Privileged user

We're ready to roll. We need to run as a privileged used because cyberprobe
captures data off the network interface. So, running as root, you need to
locate the place where you compiled the code, and run @command{cyberprobe}
giving it the name of the configuration file you just created:

@example
cyberprobe c.xml
@end example

If everything goes to plan, you should see the following output:

@example
Capture on interface eth0 started.
@end example

If you see an error message, the obvious two things to check are:

@itemize

@item
Did you name a network interface correctly? See @command{ifconfig}
discussion above.

@item
Are you running as a privileged user?

@end itemize

If you see no output at all, check that your configuration file is correct.

Once you are seeing the "Capture on interface eth0" line, then you've
achieved success in this step, and are ready to move on.

If you have everything working, there's one thing to note before moving on:
cyberprobe treats a broken configuration file the same as an empty
configuration file. With cyberprobe running, edit the configuration file,
and delete the query (@samp{?}) prefix in the first line, so that it looks like
this:

@example
<xml version="1.0" encoding="ISO-8859-1"?>
@end example

You've now broken the configuration file. It's not valid XML any more, so
the parsing fails. You should see this output from @command{cyberprobe}:

@example
Capture on interface eth0 stopped.
@end example

If you repair the damage to the configuration file, everything will start
working again. The lesson here is: If you find that @command{cyberprobe}
won't recognise any resources, it's likely that your configuration file is
invalid. The utility @command{xmlwf}x can be useful to check that an XML
configuration file is valid, if you're not getting the results you expect.

@cindex Target
@cindex @command{cyberprobe}, target
@heading Adding a target

We have @command{cyberprobe} running, but it isn't doing anything
useful. Remember, I said that a useful configuration consists of three
minimal elements: interfaces, targets and endpoints? Well, currently we only
have interfaces defined. That means that @command{cyberprobe} is capturing
packets off of the network, but throwing them away.

Let's add a target. Edit the targets block of the configuration file. We
need an entry describing the IP address of my workstation. Remember? We
discovered that with the ifconfig command earlier? Instead of
@code{192.168.1.80} use the IP address of your workstation.

@example
<targets>
  <target address="192.168.1.80" liid="123456"/>
</targets>
@end example

If successful, you should see new output from @command{cyberprobe}:

@example
Added target 192.168.1.80 -> 123456.
@end example

The target configuration allows specification of IPv4 and IPv6 addresses, and
addresses can include a mask, which allows IP address matching to be applied
in a wildcard configuration.  See @ref{@command{cyberprobe} configuration}

At this step, we're capturing packets, spotting target addresses, but as
there's no endpoint defined there's still nowhere to send the data. So, this
is still a useless configuration. On to the next step...

@heading Adding an endpoint
@anchor{Adding an endpoint}

Adding an endpoint to the configuration file will define a place where the
captured data is sent. Before adding an endpoint, let's make sure there's
something ready to receive the data.

In a separate terminal window, navigate to the @command{cyberprobe} build,
and run:

@cindex @command{etsi-rcvr}

@example
etsi-rcvr 10000 | tcpdump -n -r -
@end example

The @command{etsi-rcvr} program opens a TCP port listening on port 10000 for
a stream of ETSI data, and on standard output, writes the IP packets it sees
in PCAP format. The tcpdump command receives this PCAP data, and outputs
packet summaries.

If that starts successfully, the next step is to plumb a connection from
@command{cyberprobe} to @command{etsi-rcvr}.

Next, edit the configuration file, and edit the endpoints block to deliver
packets to a local service on port 10000:

@cindex Endpoint
@cindex @command{cyberprobe}, endpoint

@example
<endpoints>
  <endpoint hostname="localhost" port="10000"
      transport="tcp" type="etsi"/>
</endpoints>
@end example

If that worked, you should see @command{cyberprobe} start the endpoint:

@example
Added endpoint localhost:10000 of type etsi
@end example

Hopefully you'll start to see some output from tcpdump...

@heading Capturing data

At this step, @command{cyberprobe} should be forwarding an network traffic
your workstation generates to the tcpdump command, so that you see data. Any
average workstation is generating network traffic all the time, so you won't
need to do anything. But if you see nothing, you can do something like,
visit the Google home page in a browser on your workstation. You should see
something like this pouring from the tcpdump.

@example
18:54:24.376838 IP 192.168.1.80.54249 > 212.58.244.71.http: Flags [P.],
 seq 1:673, ack 1, win 115, options [nop,nop,TS val 129851063 ecr 33669
55869], length 672
18:54:24.390768 IP 212.58.244.71.http > 192.168.1.80.54249: Flags [.], 
ack 673, win 124, options [nop,nop,TS val 3366955882 ecr 129851063], le
ngth 0
18:54:24.392909 IP 212.58.244.71.http > 192.168.1.80.54249: Flags [P.],
 seq 1:1796, ack 673, win 124, options [nop,nop,TS val 3366955884 ecr 1
29851063], length 1795
@end example

At this step, it's worth having a quick play with the reconnection
mechanism. Stop and start @command{etsi-rcvr}, and you'll see that
@command{cyberprobe} reconnects automatically:

@cindex Connection reset
@cindex Connection restart
@cindex Reconnection

@example
ETSI LI connection to localhost:10000 failed.
Will reconnect...
ETSI LI connection to localhost:10000 established.
@end example

We don't guarantee zero data loss on a reconnect.

@comment ----------------------------------------------------------------------

@node Management interface
@section Management interface
@cindex Management
@cindex @command{cyberprobe}, management

At this step, we'll setup a control port, and use it modify the
configuration of @command{cyberprobe}.

First step is to modify the configuration file to include this line, just
after the @code{<configuration>} line:

@cindex Authentication

@example
<control port="8888" username="admin" password="mypassword"/>
@end example

That declares that a management service needs to be run on port 8888. The
authentication details are provided too. You should see this output from
@command{cyberprobe}:

@example
Starting control on port 8888
@end example

That's good! Now need to connect and interrogate the targets list: I use
telnet to connect, the auth command to authenticate, and the target command
to see a list of commands.

@example
$ telnet localhost 8888
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
auth admin mypassword
200 Authenticated.
targets
201 Targets list follows.
25
123456:ipv4:192.168.1.80/32
@end example

I can use the help command to see the full list of commands permitted. There
are commands for changing the address target list:

@example
targets
201 Targets list follows.
25
123456:ipv4:192.168.1.80
remove_target ipv4 192.168.1.80
200 Removed target.
add_target 654321 ipv4 192.168.0.0/16
200 Added target.
@end example

The interface isn't pretty, but you get the idea. You can change almost
everything that you can manage by changing the configuration file.

Note: The the management interface changes the active state of
@command{cyberprobe} but it doesn't change the configuration file. So,
configuration changes made through the management interface are 'lost' when
you restart @command{cyberprobe}.

Note also that you may get some weird results if you use the configuration
file AND the control interface to manage the same resources, so you probably
don't want to do that.

@cindex @command{cyberprobe-cli}

The @command{cyberprobe-cli} command can be used to access the
management interface but provides a (slightly) nicer @code{readline}
interface, and has auto-completion.  Usage is of the form
@example
cyberprobe-cli @var{host} @var{port}
@end example
Once you're in, you can type help to get help, or press TAB for auto-completion
of commands.

@comment ----------------------------------------------------------------------

@node Integration with @command{snort}
@section Integration with @command{snort}
@cindex @command{snort}, integration
@cindex Integration with @command{snort}

In this step, we'll add the excellent IDS, Snort to the mix. If you don't
know Snort, it scans network traffic for patterns, and can take various
actions when those patterns are discovered. It is typically used to detect
network attacks, and the Snort folks maintain a huge collection of patterns
that will identify known network attacks. The Snort team maintain the
project at @url{http://www.snort.org}.

If you want to try out the Snort integration, you need to head over to the
Snort home page, download and install Snort.  Or install the appropriate
package with your distribution.

Once you have it installed, to simplify things, you'll want to put a
rule in place that will definitely identify things on your
network. The easiest way is to add a local rule that identifies your
workstation. First of all, you'll want to make sure your Snort
configuration file (probably @file{/etc/snort/snort.conf}) loads a
local rules file. So, it should contain something like this:

@cindex @command{snort}, rules
@cindex @command{snort}, signatures

@example
# site specific rules
include $RULE_PATH/local.rules
@end example

Then, to identify your workstation, add a rule like this to your local rules
file (probably @file{/etc/snort/rules/local.rules}):

@example
alert tcp 192.168.1.80 any -> any 80 (msg:"Web"; 
classtype:misc-activity;sid:200; rev:1;)
@end example

@command{cyberprobe} itself needs to be configured to receive Snort
alerts. You do that by adding some configuration, just after the
<configuration> line:

@example
<snort_alert socket="/var/log/snort/snort_alert" duration="60"/>
@end example

That says, Snort alerts will result in dynamic collection of data for 60
seconds from identification. While you're in the configuration file, you can
remove the static IP address target line. Find this line and delete it:

@example
<target address="192.168.1.80" liid="123456"/>
@end example

@command{cyberprobe} should respond:

@cindex @command{snort} alerts

@example
Removed target 192.168.1.80 -> 123456.
Start snort alerter on /var/log/snort/snort_alert
@end example

Now I can run Snort in IDS mode. Snort needs to run as 'root':

@example
snort -i eth0 -A unsock -N -l /var/log/snort/ -c /etc/snort/snort.conf
@end example

Thanks to our Snort rule, when our workstation generates network data, Snort
will detect it, trigger our rule, and alert @command{cyberprobe}. You should
see @command{cyberprobe} say:

@example
Hit on signature ID 200, targeting 192.168.1.80
@end example

Also, once the rule is triggered, you should see evidence of packet data
from the @command{tcpdump} command, as before. @command{cyberprobe} causes
the targeting to time out after a period of time. If further alerts are
seen, the targeting lifetime is targeted. If no further alerts are seen the
IP address targeting is deleted. If you can convince your workstation to
stop creating network data, by e.g. not using it for a minute or so, then
you should see the rule time out:

@example
Stopped targeting on 192.168.1.80
@end example

In practice this may be harder than you think, as workstations generate
network traffic all the time. You may have to turn off your email clients
and close the web browse. Your attempt to silence your workstation may be
further thwarted by the operating system checking for patches without you
knowing.

@cindex @command{cyberprobe}, delay
@cindex Delay
@heading Introducing a delay

Your Snort integration suffers from a particular problem now. The time taken
for Snort to inspect some packets, generate an alert and for
@command{cyberprobe} to get the IP address targeted is not zero. It is hard
to measure, but it is going to be a significant chunk of a millisecond. The
problem is that by the time @command{cyberprobe} is targeting the IP
address, the network attcker's packets have long gone. The result is, that
while @command{cyberprobe} is now targetting the attacker, it won't capture
the original network attack.

Our solution is to introduce a packet delay in @command{cyberprobe}. The
packets entering @command{cyberprobe} are kept in a time-delay queue and are
processed once that delay expires. You can configure a delay, by putting the
delay attribute in an interface specfication. e.g.

@example
<interfaces>
  <interface name="eth0" delay="0.2"/>
</interfaces>
@end example

0.2 second should be plenty enough. You should be able to see this delay in
action: When you generate network traffic, you should be able to see the
delay between network activity taking place, and the corresponding burst of
activity from tcpdump.

At this point, you've completed the guided tour of @command{cyberprobe}, the
packet capture tool. If that's all you need, the rest of the tutorial will
probably have less interest to you: In the following steps, we'll start to
analyse and act on the captured data.

@comment ----------------------------------------------------------------------

@node Using @command{cybermon}
@section Using @command{cybermon}
@cindex @command{cybermon}
@cindex @command{cybermon}, configuration
@heading Introducing @command{cybermon}

The previous 9 steps have all been about @command{cyberprobe}. If you've got
this far successfully, you pretty much know all there is to know about
@command{cyberprobe}. It is time to start doing something more useful with
all that data you are capturing. In this step we'll start up
@command{cybermon} and look at the data.

@cindex @file{monitor.lua}

Remember that @command{etsi-rcvr} command you started in step @ref{Adding an
endpoint}? Stop that, and start @command{cybermon}. Two arguments are
needed: A TCP port number to receive the data on, and a configuration which
tells it what to do. A number of configuration files are bundled in with the
source code, there should be a basic one called @file{monitor.lua} which
is now installed in the etc directory, depending on where you installed the
software:

@example
cybermon -p 10000 -c @value{SYSCONFDIR}/cyberprobe/monitor.lua
@end example

Now when you generate network traffic, some of the traffic will be presented
in a reasonably intelligent form. For example, I do a naming service lookup
for @code{www.google.com}...

@example
host -t a www.slashdot.org
@end example

@cindex DNS

The DNS protocol is parsed, and presented in a human readable form. I can
see the request, and the response:

@example
SNORTc0a80150: 192.168.1.80:54633 -> 192.168.1.1:53. DNS query
    Query: www.slashdot.org

SNORTc0a80150: 192.168.1.1:53 -> 192.168.1.80:54633. DNS response
    Query: www.slashdot.org
    Answer: www.slashdot.org -> 216.34.181.48
@end example

I see the query travelling from my workstation to the broadband router, and
then the response from the broadband router contains an answer field mapping
the name to an address. HTTP protocols are also decoded. Get the Slashdot
home page...

@example
wget -O- 'http://www.slashdot.org/'
@end example

...and amongst all the other stuff, you see the HTTP request and response...

@example
SNORTc0a80150: 192.168.1.80:34284 -> 216.34.181.45:80. HTTP GET request
    URL /
    Connection: Keep-Alive
    User-Agent: Wget/1.14 (linux-gnu)
    Host: slashdot.org
    Accept: */*

SNORTc0a80150: 216.34.181.45:80 -> 192.168.1.80:34284. HTTP response 200
OK
    URL http://slashdot.org/
    Connection: keep-alive
    Content-Length: 113468
    Date: Mon, 26 Aug 2013 13:13:25 GMT
    Age: 17
    X-Varnish: 1493567531 1493567417
    X-XRDS-Location: http://slashdot.org/slashdot.xrds
    Cache-Control: no-cache
    Vary: Accept-Encoding
    SLASH_LOG_DATA: shtml
    Pragma: no-cache
    Content-Type: text/html; charset=utf-8
    Server: Apache/2.2.3 (CentOS)
@end example

@heading Trying other configuration files

In the previous step, you started @command{cybermon} with the
@file{monitor.lua}
configuration file. Have a play with a couple of the others. Configuration
file @file{hexdump.lua} produces little hex dumps of things like HTTP bodies.

@cindex @file{hexdump.lua}

@example
cybermon -p 10000 -c @value{SYSCONFDIR}/cyberprobe/hexdump.lua
@end example

Configuration file @file{json.lua} causes @command{cybermon} to output the
events as JSON objects.

@example
cybermon -p 10000 -c @value{SYSCONFDIR}/cyberprobe/json.lua
@end example

The @file{quiet.lua} configuration file does nothing. It may be a good place
to start hacking your own configuration file. Which is exactly what we'll do
in the next step.

@comment ----------------------------------------------------------------------

@node Writing your own configuration file
@section Writing your own configuration file

Now, take a copy of the @file{quiet.lua} configuration file, and have a look
at it. It consists of a bunch of functions written in the LUA language. LUA
is a lightweight scripting langauge which is really good as a configuration
language. For example, this function is called when a TCP connection is
made:

@cindex @code{connection_up}
@cindex @code{http_response}

@example
observer.connection_up = function(context)
end
@end example

And this function is called when an HTTP response is observed:

@example
observer.http_response = function(context, code, status, header, url,
                                  body)
end
@end example

Let's get hacking! The header parameter is a LUA table which contains
key/value pairs from the header. The url parameter contains the full URL of
the response. The body parameter contains the payload body as an empty
string. Let's start simple:

@example
observer.http_response = function(context, code, status, header, url,
                                  body)
  print(url)
end
@end example

Then run that up...

@example
cybermon -p 10000 -c my.lua
@end example

Now, do some web browsing, and you should see a list of URLs flying
past. Each web page typically consists of several HTTP requests, but you
should be able to see the URLs associated with all of the web pages you
visit. Let's tart that up a little more:

@example
-- This function is called when an HTTP response is observed.
observer.http_response = function(context, code, status, header, url,
                                  body)

  -- Take first 40 characters of URL
  local u = url:sub(1,40)

  -- Get Content-Type (first 20 characters)
  local ct
  ct = ""
  for key, value in pairs(header) do
    if key:lower() == "content-type" then
      ct = value:sub(1,20)
    end
  end

  io.write(string.format("%-40s %-20s %d\n", u, ct, #body))

end
@end example

That basically outputs three columns: The URL (truncated to 40 characters),
the body content type (truncated to 20 characters) and the HTTP response
payload length. Here's what I get from visiting Slashdot:

@example
http://widget-cdn.rpxnow.com/manifest/sh text/javascript;char 42980
http://slashdot.org/                     text/html; charset=u 40105
http://ad.doubleclick.net/adj/ostg.slash text/javascript; cha 5625
http://pagead2.googlesyndication.com/pag application/x-shockw 33347
http://ad.doubleclick.net/adj/ostg.slash text/javascript; cha 540
http://ad.doubleclick.net/adj/ostg.slash text/javascript; cha 42
http://ad.doubleclick.net/adj/ostg.slash text/javascript; cha 452
http://pagead2.googlesyndication.com/pag                      0
@end example

@heading Forging a TCP reset

So far, this has just been monitoring. It's time to add data to the network!
From the LUA functions, there are a couple of functions available which
allow you to put some packets back onto the network.

@cindex TCP reset
@cindex Packet forgery
@cindex Packet injection
@cindex @command{cyberprobe}, delay
@cindex Delay

But first... there's a problem. You remember in step 9, we added a delay?
That's not going to work with packet forgery, because by the time we've
forged a packet and sent it on to the network, it's too late. So, we need to
change our interface back so that there's no delay on the interface. That
means, we're monitoring network data, but we'll miss the original attack
which triggered a Snort alert.

@example
<interface name="eth0" delay="0.0"/>
@end example

Once you have this code working, you might be able to mess with the delay
parameter to see if you can pick a low-latency value that works for you. On
my network, the value 0.02 is low enough to allow a response to allow packet
forgery to work. Any higher, and the forged packets are too late to beat the
real packets.

The LUA interface passes a context variable to many of the LUA functions,
which gives access to @command{cybermon} information and the packet forgery
functions. In this step, we're going to forge a TCP reset on any connections
which are from or to port 80. Hack the configuration file:

@cindex @code{context}

@example
observer.connection_up = function(context)

    -- Get TCP ports.
    local cls, src_addr, dest_addr
    cls, src_addr = context:get_src_addr()
    cls, dest_addr = context:get_dest_addr()

    -- check if it is port 80.
    if not((src_addr == "80") or (dest_addr == "80")) then
      -- Ignore non-HTTP traffic
      return
    end

    -- TCP reset    
    print("Reset on HTTP connection.")
    context:forge_tcp_reset(context)

end
@end example

Now before we go any further, @command{cybermon} needs to run as root in
order to use either of the packet forgery functions. Packet forgery needs
access to the raw IP socket layer, which is a privileged operation. Start
that up:

@example
cybermon -p 10000 -c my.lua
@end example

Now start web browsing, and you should see a bunch of "Reset on HTTP
connection" messages. Also, you'll see a page saying "The connection was
reset" in your web browser. That's a fairly anti-social configuration to run
on any network. See the @file{forge-reset.lua} example for a more useful
configuration. It disrupts network traffic going to/from an SSH server which
isn't from your administration workstation.

On any network with an SSH service open to the outside world, you might want
to use firewall rules to prevent access to the SSH service from addresses
outside of your network, but you could use @command{cybermon} as a
belt-and-braces protection mechanism.

Another example is where you know the user community on your network is
being targeted by phishing emails. Your first step is to try to get the
phishing emails out of their inboxes, getting your email provider to filter
the attacks. But a backup attack would be to make sure your users can't get
to the phisher's web site. The http_request function allows us to reset
requests going to a particular web site.

@example
-- This function is called when an HTTP request is observed.
observer.http_request = function(context, method, url, header, body)

    if header["Host"] == "example.org" then
      print("Reset on HTTP request")
      context:forge_tcp_reset(context)
    end

    if header["Host"] == "www.example.org" then
      print("Reset on HTTP request")
      context:forge_tcp_reset(context)
    end

end
@end example

@heading Forging a DNS response

@cindex Forging, DNS response

In this step, we'll detect a particular DNS request, and forge a
response. First of all, you'll need to familiarise yourself with host which
is a useful DNS test tool. e.g.

@example
$ host -t a example.org
example.org has address 93.184.216.119
@end example

The @code{example.org} name has been resolved to a particular IP
address. Let's hack the DNS request function in @file{my.lua}:

@cindex @code{dns_message}

@example
-- This function is called when a DNS message is observed.
observer.dns_message = function(context, header, queries, answers, auth,
                                add)

  -- Check my assumptions.  Need a DNS query request, with one query,
  -- name is example.org, type 'A', class 'IN'.
  if header.qr == 0 and #queries == 1 and
    queries[1].name == "example.org" and queries[1].type == 1 and
    queries[1].class == 1 then

    -- Send a fake response

    -- Set query/response flag to 'response'
    header.qr = 1

    -- 1 answer
    answers = @{@}
    answers[1] = @{@}
    answers[1].name = "example.org"
    answers[1].type = 1
    answers[1].class = 1
    answers[1].rdaddress = "1.2.3.4"

    -- 1 answer
    header.ancount = 1

    io.write("Forging DNS response!\n")

    context:forge_dns_response(context, header, queries, answers,
                               @{@}, @{@})

  end

end
@end example

So, this example, checks that the query is one we want to mess with. If it
is, we turn the query structures into response structures, and hand them
back to @command{cybermon} to do a forgery. The above example forges the
address @code{1.2.3.4}. Start up @command{cybermon} with the script:

@example
cybermon -p 10000 -c my.lua
@end example

If everything is working your host command will show a different result:

@example
$ host -t a example.org
example.org has address 1.2.3.4
@end example

DNS forgery has applications in blocking access to a phishers
resources on the internet, you might want to redirect your users to an
address which is inside your network.

The @ref{@command{cybermon} configuration} documentation details the LUA
interface in detail if
you want to find out what else you can do in your LUA code.

@comment ----------------------------------------------------------------------

@node Visualisation
@section Visualisation
@cindex Visualisation
@cindex ElasticSearch
@cindex Storing observations

@heading Storing observations

Now we need somewhere to store the observations which @command{cybermon}
discovers. There are many candidates for a storage repository, but my
favourite for this sort of scenario is the excellent ElasticSearch (
@url{http://www.elasticsearch.org/}). It is flexible, offers a huge amount
of functionality, and is incredibly simple to interface with, thanks to its
JSON API. So, your next action is to head over to the download page
(@url{http://www.elasticsearch.org/download/}) and get hold of the latest
version. I'm using version 6.1 to build this tutorial but the
ElasticSearch API has proven hugely stable, so should work with the latest.

The easiest way to run ElasticSearch is as a Docker container, although you
could download and run the distribution.

@example
docker run --name elasticsearch -p 9200:9200 \
  docker.elastic.co/elasticsearch/elasticsearch-oss:6.1.1
@end example

One brilliant thing about ElasticSearch is that it needs almost no
configuration to get an instance started. You will need to make one
configuration change to ElasticSearch if there are other instances running
on your network: you need need to change @code{cluster.name} to some unique
string in @file{config/elasticsearch.yml}, otherwise your ElasticSearch
instance might join another cluster on your network, which could complicate
things.

You can check you have ElasticSearch up and running using a command such as
this:

@example
wget -q -O- http://localhost:9200
@end example

The response will look something like this:

@cindex JSON

@example
@{
  "name" : "gAbVXGZ",
  "cluster_name" : "docker-cluster",
  "cluster_uuid" : "TPZLBGYnTNqe0-LVLiF6yw",
  "version" : @{
    "number" : "6.1.1",
    "build_hash" : "bd92e7f",
    "build_date" : "2017-12-17T20:23:25.338Z",
    "build_snapshot" : false,
    "lucene_version" : "7.1.0",
    "minimum_wire_compatibility_version" : "5.6.0",
    "minimum_index_compatibility_version" : "5.0.0"
  @},
  "tagline" : "You Know, for Search"
@}
@end example

Once ElasticSearch is running, you can get @command{cybermon} to load
observations into it.  Before we do that, need RabbitMQ to provide the
pub/sub infrastructure:

@example
docker run --name amqp -p 5672:5672 -p 15672:15672 \
    docker.io/library/rabbitmq:3.7.4-management
@end example

Next we need to run two commands.
Firstly, @command{cybermon} is run to output events on a RabbitMQ
pub/sub queue.

@example
cybermon -p 10000 -c @value{SYSCONFDIR}/cyberprobe/amqp-topic.lua
@end example

While that's running, we can start the ElasticSearch loader:

@example
cybermon-elasticsearch cyberprobe
@end example

After some network data has been observed, you should be able to see results
loaded into ElasticSearch using the following command:

@example
es=localhost:9200
curl -s -XPOST \
  "http://$es/cyberprobe/_search?pretty=true" -d '
@{
  "query" : @{
    "match_all": @{@}
  @}
@}
'
@end example

You should see some stuff which looks like data scrolling past on the
screen. If your response looks like the following result, that's not so
good, as it means there are no results. See @code{hits.total}? Zero means no
results.

@example
@{
  "took" : 1,
  "timed_out" : false,
  "_shards" : @{
    "total" : 5,
    "successful" : 5,
    "failed" : 0
  @},
  "hits" : @{
    "total" : 0,
    "max_score" : null,
    "hits" : [ ]
  @}
@}
@end example

If you see a lot of information scrolling past on the screen, that's good.

@command{cybermon-elasticsearch} maps the @command{cybermon}
observations into a form which is appropriate to store in
ElasticSearch. 

@cindex Kibana, dashboard
@cindex Dashboard
@heading Visualising observations

Having loaded the observations into ElasticSearch, it's easy to do some
visualisation with Kibana. Kibana is a brilliant, user-configurable
dashboard package designed to sit on ElasticSearch. The dashboard runs in
your browser.

First thing to do is to run up a Kibana container.  Kibana is made by the
ElasticSearch people, download page is at
@url{http://www.elasticsearch.co/downloads/kibana}.

Run a Kibana container:

@example
docker run --name kibana \
  -e ELASTICSEARCH_URL=http://elasticsearch:9200/ -p 5601:5601 \
  --link elasticsearch:elasticsearch \
  docker.elastic.co/kibana/kibana-oss:6.1.1
@end example

Kibana starts on port 5601, so point your browser at e.g.
@url{http://localhost:5601}

and hopefully you see Kibana's "Welcome to Kibana" screen.

Read the Kibana tutorial and start playing with the data.
First thing you need to do is
create a @code{cyberprobe} index with the time field @code{time}.
The go to the Visualize tab to see raw data.

Once you have data loading into ElasticSearch, you may want to install
our basic dashboards.  These are installed at:
@example
@file{@value{DOCDIR}/kibana-dashboards.json}
@end example

@comment ----------------------------------------------------------------------

@node Threat indicators using STIX
@section Threat indicators using STIX
@cindex STIX
@cindex TAXII
@cindex STIX indicators
@cindex Threat indicators
@cindex Cyber threat indicators
@cindex JSON

We've been experimenting with an open model for describing cyber
threats. STIX is a community-driven effort to standardise a model for cyber
theat information. TAXII defines a set of services for distributing STIX
information. There's some support in @command{Cyberprobe}, but you should
know that this is very prototype at the moment.

This is what we've got so far:

@itemize

@item
There's a simple CSV file format we've created to describe cyber
threats. This is just for convenience.

@cindex @command{stix-create}
@item
A script, @command{stix-create} which reads the above configuration file,
and converts into a STIX document containing Indicator objects.

@cindex @command{taxii-server}
@item
A script, @command{taxii-server} which acts as a very simple TAXII server,
serving up STIX documents.

@cindex @command{taxii-client}
@item
A script, @command{taxii-client} which connects to a TAXII server, gets STIX
documents and dumps some stuff out.

@cindex @command{taxii-sync-json}
@item
A script @command{taxii-sync-json} which connects to a TAXII server, gets
STIX documents, massages the whole lot into a single JSON form, and dumps
that to a file.  This is intended to be used with the
@file{cybermon-detector} subscriber.
See @ref{@command{cybermon-detector} invocation}.

@item
A configuration file for @command{cybermon} which reads the JSON threat
information and reports when theats are observed.

@end itemize

@cindex @code{pyOpenSSL}
@cindex @code{libtaxii}
@cindex @code{stix}
@cindex @code{pip}

Before taking this any further, you need to have Python installed, along
with various dependencies (@code{pyOpenSSL}, @code{libtaxii} and
@code{stix}). The easiest way to install the dependencies is to install
@code{pip}, and issue this command:

@example
sudo pip install libtaxii pyOpenSSL stix
@end example

@heading A STIX document service

The installation bundle includes a couple of CSV files containing some
fictional cyber theats. Search for @file{example1.txt} and
@file{example2.txt}. They may be in @file{@value{PREFIX}/share/doc/cyberprobe}
once you've installed everything. You need to create a data area, and
convert these files into STIX ready for serving:

@example
mkdir /tmp/stix
cd /tmp/stix
mkdir -p data/default
stix-create @value{PREFIX}/share/doc/cyberprobe/example1.txt \
        data/default/1 -i ex:1
stix-create @value{PREFIX}/share/doc/cyberprobe/example2.txt \
        data/default/2 -i ex:2
@end example

Check that you have two new XML files in data/default directory. If they're
there, you're ready to start a STIX server. This will run on port 8080, so
you'll need to use a different port number if you don't like this one. It's
important that this is run from the directory where you just created the
data directory.

@example
taxii-server --port 8080
@end example

If that works, use the test client to communicate:

@example
taxii-client --port 8080 --poll
@end example

And you should see some stuff that looks like cyber threat information
dumped on the screen.

@heading Deploying theat information to @command{cybermon}

@cindex JSON

Now, we use @command{taxii-sync-json} to fetch the STIX information in a
JSON form I can easily ingest into the LUA code:

@example
taxii-sync-json --port 8080
@end example

This will create a JSON file called @file{stix-default-combined.json}.

Finally, run processing.  Stop any running @command{cybermon} and
@command{cybermon-elasticsearch} processes.  Then run @command{cybermon}
to publish to a queue on RabbitMQ:

@example
cybermon -p 10000 -c @value{SYSCONFDIR}/cyberprobe/amqp-topic.lua
@end example

Next run @command{cyberprobe-detector} to apply STIX rules.  By default,
this will subscribe to @samp{cyberprobe} and publish to @samp{ioc}:

@example
STIX_INDICATORS=stix-default-combined.json cybermon-detector \
    cyberprobe ioc
@end example

Finally, in order to look at the output, we need to subscribe to
@samp{ioc}:

@example
cybermon-dump ioc
@end example

If you have @command{jq} installed, this will make it easier to see
when indicators hit:

@example
cybermon-dump ioc | jq --unbuffered .indicators
@end example

This activity should trigger a theat:

@example
wget -q -O- http://www.malware.com/malware.dat
@end example

If this works, you should see the following output:

@example
[
  @{
    "type": "url",
    "id": "example1:7",
    "value": "http://www.malware.com/malware.dat",
    "description": "URL of a page serving malware"
  @}
]
@end example

This hits on a number of theat indicators. The hostname www.malware.com is
present in a theat indicator, and it is detected in the HTTP request, and
both the DNS query and response. Also, the URL
@code{http://www.malware.com/malware.dat} is in a threat indicator and it is
detected in both the HTTP request and response.

@command{cybermon-detector} updates its state if
the JSON configuration file has changed. So, you can do a round-trip update
by changing the input files, re-running stix-create, using
@command{taxii-sync-json} to fetch the updates, and all without stopping the
monitoring.

If you want to load the output of @command{cybermon-detector} into
ElasticSearch, you can, but you need to subscribe to @samp{ioc}:

@example
cybermon-elasticsearch ioc
@end example

@heading Conclusion

All done, I hope you enjoyed the tutorial! Any comments on the software, or
tutorial itself are very welcome! Positive, or negative, we want to hear how
you found the experience.

@comment ----------------------------------------------------------------------

@node Running cyberprobe/cybermon
@chapter Running cyberprobe/cybermon

The @command{cyberprobe} and @command{cybermon} utilities are used as a pair
to analyse network data.  The @command{cyberprobe} component is used to
capture data and forward to @command{cybermon}.  When running on a network,
you can decide to run several @command{cyberprobe} deployments into a single
@command{cybermon}.  Or run a @command{cybermon} process everywhere you
run a @command{cyberprobe}.

Once you have decided your checklist, your setup checklist for using
@command{cyberprobe} and @command{cybermon} consists of:

@itemize

@item
Install the software, see @ref{Obtaining the software}.

@item
If you are going to run @command{cyberprobe}, provide the appropriate
configuration
in file
@file{@value{SYSCONFDIR}/cyberprobe.cfg}.  The standard installation
will install a template at this location.
See @ref{@command{cyberprobe} configuration} on managing this configuration
file.
Make sure that the configuration file includes the delivery address of the
appropriate @command{cybermon}.

@item
@cindex @command{cybermon}, pub/sub
@cindex Pub/sub delivery
If you are going to run @command{cybermon}, provide the
appropriate configuration in file
@example
@file{@value{SYSCONFDIR}/cyberprobe/cybermon.lua}.
@end example
The standard installation
does not create a file at this location, and you should create one.  You can
copy an example from the @file{@value{SYSCONFDIR}/cyberprobe} directory.
Use @file{@value{SYSCONFDIR}/cyberprobe/amqp-topic.lua} if you want to use
pub/sub delivery.  See @ref{@command{cybermon} configuration} for more
information on constructing the configuration file.
See @ref{@command{cybermon} example configurations} for descriptions of the
example configuration files.

@item
The installation installs appropriate @command{systemd} configuration, and
you can enable boot-time starting of @command{cyberprobe} or
@command{cybermon} by using either or both of these commands:
@example
systemctl enable cyberprobe
systemctl enable cybermon
@end example
Once enabled, you can reboot, or immediately start the processes using either
or both of these commands:
@example
systemctl start cyberprobe
systemctl start cybermon
@end example

@end itemize

@comment ----------------------------------------------------------------------

@node The pub/sub infrastructure
@chapter The pub/sub infrastructure

@menu
* Pub/sub overview::
* The Cassandra subscriber::
* The ElasticSearch subscriber::
* The Gaffer subscriber::
* The Google BigQuery subscriber::
* The debug monitor subscriber::
@end menu

@comment ----------------------------------------------------------------------

@node Pub/sub overview
@section Pub/sub overview

@cindex @command{cybermon}, pub/sub
@cindex Pub/sub delivery

Events from @command{cybermon} can be delivered to a pub/sub mechanism which
allows subscribers to connect and disconnect without disrupting delivery
to other subscribers.  The pub/sub mechanism used is RabbitMQ, which is a
simple non-persistent, broker-less mechanism.

In order to use this mechanism, you need to ensure you have configured
@command{cybermon} appropriately.  This is normally done by copying the
@file{amqp-topic.lua} to @file{cybermon.lua} in directory
@file{@value{SYSCONFDIR}/cyberprobe/}.
prior to executing
@command{cybermon}.  Alternatively, @command{cybermon} can be manually
invoked, specifying the @file{amqp-topic.lua} pathname on the command line.

Once running, @command{cybermon} will publish all events
to RabbitMQ.

RabbitMQ allows subscribers to be started and stopped without affecting the
delivery of events to other receivers.  That is, you can start
@command{cybermon} with no subscribers, discarding data, and introduce
subscribers later.

For more advanced processing scenarios, multiple pub/sub components can be
chained.  e.g.

@itemize @bullet

@item
@command{cybermon} can be executed with @file{amqp-topic.lua} to publish
events to RabbitMQ queue @samp{cyberprobe}.

@item
@command{cybermon-geoip} can subscribe to @samp{cyberprobe}, and push
events containing information to @samp{geo}.

@item
@command{cybermon-detector} can lookup for IOCs and push events with IOC
detection information to @samp{ioc}.

@item
@command{cybermon-elasticsearch} can subscribe to @samp{ioc} and write events to
ElasticSearch.

@end itemize

@comment ----------------------------------------------------------------------

@node The Cassandra subscriber
@section The Cassandra subscriber

@quotation Note
The Cassandra subscriber doesn't do much useful.  I recommend skipping this
bit.
@end quotation

@cindex @command{cybermon-cassandra}, invocation
@cindex Cassandra
@cindex Apache Cassandra
@cindex Graph store

This subscriber writes data to a Cassandra store in a schema useful for
graph analysis.

The schema is experimental, but see
@url{https://github.com/cybermaggedon/cassandra-redland} for the tooling
I'm using.

On the command-line you need to tell the subscriber the location
of the Cassandra contact points e.g.

@example
cybermon-cassandra ioc cas1,cas2,cas3
@end example

See @ref{@command{cybermon-cassandra} invocation}.


@comment ----------------------------------------------------------------------

@node The ElasticSearch subscriber
@section The ElasticSearch subscriber

@cindex @command{cybermon-elasticsearch}, invocation
@cindex ElasticSearch

This suscriber extracts events from pub/sub and formats them for delivery
to ElasticSearch.  The only piece of information you need is the ElasticSearch
base URI, which is used as a command-line parameter e.g.

@example
cybermon-elasticsearch ioc http://es-host1:9200
@end example

See @ref{@command{cybermon-elasticsearch} invocation}.

@comment ----------------------------------------------------------------------

@node The Gaffer subscriber
@section The Gaffer subscriber

@cindex @command{cybermon-gaffer}, invocation
@cindex Gaffer
@cindex Graph store

@heading About Gaffer

Gaffer is a graph database built on top of Accumulo, Zookeeper
and Hadoop.  This subscriber writes IP, TCP and UDP communication information
into the
graph.  If you want to use this, get familiar with Gaffer.
Gaffer development is hosted on Github at
@url{https://github.com/gchq/Gaffer}, and I maintain Gaffer containers here:

@table @url

@item https://hub.docker.com/r/cybermaggedon/wildfly-gaffer/
Gaffer component, provides REST interface running in a Wildfly container.

@item https://hub.docker.com/r/cybermaggedon/accumulo-gaffer/
Accumulo component, with added Gaffer operator library which is necessary
to be able to use Gaffer on Accumulo.

@item https://hub.docker.com/r/cybermaggedon/zookeeper/
Zookeeper container, which is required by Accumulo.

@item https://hub.docker.com/r/cybermaggedon/hadooop/
Hadoop container, which is required by Accumulo.

@end table

@heading Running Gaffer

To get started, you can run a Gaffer system by launching with the minimal
set of containers:

@example

GAFFER_VERSION=1.1.2

# Run Hadoop
docker run -d --name hadoop cybermaggedon/hadoop:2.8.1

# Run Zookeeper
docker run -d --name zookeeper \
      cybermaggedon/zookeeper:3.4.10b

# Run Accumulo
docker run -d --name accumulo --link zookeeper:zookeeper \
      --link hadoop:hadoop \
      cybermaggedon/accumulo-gaffer:$@{GAFFER_VERSION@}

# Run Wildfly, exposing port 8080.
docker run -d --name wildfly --link zookeeper:zookeeper \
  --link hadoop:hadoop --link accumulo:accumulo \
  -p 8080:8080 \
  cybermaggedon/wildfly-gaffer:$@{GAFFER_VERSION@}

@end example

The Gaffer/Wildfly component takes about 30 seconds to bed in.  Once working,
you can check the status of Gaffer by interacting with the REST API.  This
command should return the Graph schema, which is a JSON object:

@example
wget -q -O- http://localhost:8080/rest/v1/graph/schema
@end example

You can fetch the entire graph using this command.  Initially, the graph will
be empty.  This command may take a long while to run once the graph is loaded
with loads of data:

@example
wget -q -O- --header 'Content-Type: application/json' \
  --post-data '
  @{"class": "uk.gov.gchq.gaffer.operation.impl.get.GetAllElements"@}
  ' http://localhost:8080/rest/v2/graph/operations/execute
@end example

@heading Linking to @command{cybermon}

On the command-line you need to tell the subscriber the location
of the Gaffer REST API. e.g.

@example
cybermon-gaffer ioc \
    http://localhost:8080/rest/v1
@end example

See @ref{@command{cybermon-gaffer} invocation}.

@comment ----------------------------------------------------------------------

@node The Google BigQuery subscriber
@section The Google BigQuery subscriber

@cindex @command{cybermon-bigquery}, invocation
@cindex Google BigQuery
@cindex Google Cloud Platform

Google BigQuery is a cloud data storage mechanism which is part of the
Google Cloud Platform, available to Google Cloud subscribers.

BigQuery is a 'big data' relational style database, with a query language
familiar to SQL users.

To use BigQuery, you need to get a private key file in private JSON format
from the cloud interface, and store this at
@file{@value{SYSCONFDIR}/cyberprobe/private.json}.  One way to do this is
to go to the IAM interface and create a use with BigQuery access, and download
the private JSON file.

You need to also to create the BigQuery dataset.  Call it @samp{cyberprobe}.
The BigQuery table is created automatically when the subscriber is started.

If the key is installed at the above location, you do not need to
provide any further parameters on the command line.  Just run:

@example
cybermon-bigquery
@end example

See @ref{@command{cybermon-bigquery} invocation}.

@comment ----------------------------------------------------------------------

@node The debug monitor subscriber
@section The debug monitor subscriber

@cindex @command{cybermon-monitor}, invocation

The @command{cybermon-monitor} subscriber is a subscriber which takes
events and writes human-readable output on standard output.  This is a
useful means to verify that @command{cyberprobe}, @command{cybermon} and
pub/sub are configured correctly.

See @ref{@command{cybermon-monitor} invocation}.

@comment ----------------------------------------------------------------------

@node A containerised processing system
@chapter A containerised processing system

@heading Cybermon, Gaffer, ElasticSearch

@cindex Containers
@cindex Docker
@cindex Docker compose
@cindex @file{docker-compose.yml}
@cindex @file{docker-compose-cp-snort.yml}
@cindex ElasticSearch
@cindex Gaffer

The @command{cybermon}, subscriber components and data stores can easily be
deployed in containers to form a scalable processing system.

To illustrate this in use, we distrubute a Docker Compose configuration which
can be used to start:

@itemize @bullet

@item
A @command{cybermon}, listening on port 9000.

@item
A @command{cybermon-geoip} container, adding GeoIP information to events.

@item
A @command{cybermon-detector} container, adding IOC information to events
from a sample STIX data set.

@item
A @command{cybermon-elasticsearch} container, to load information into
ElasticSearch.

@item
A @command{cybermon-gaffer} container, to load information into Gaffer.

@item
An @command{elasticsearch} container to store events.

@item
A @command{kibana} container to store events.

@item
A Gaffer cluster consisting of Hadoop, Zookeeper, Accumulo and Gaffer
containers.

@end itemize

You can see the Docker Compose configuration at the path:

@example
@file{@value{DOCDIR}/docker-compose.yml}
@end example

In order to invoke this run:

@example
cd @file{@value{DOCDIR}/}
docker-compose up
@end example

No data is stored persistently - you can change how this works by
changing the @file{docker-compose.yml} file.
It takes about a minute to settle down, at which point, you need to generate
data using cyberprobe and send to port 9000.

You can connect to the Kibana instance on port 5601.  The first thing you will
need to do is to go to the Management > Index Patterns dialogue, and create
an index pattern for index @samp{cyberprobe}, with time specified in the
@samp{time} field.

You may want to install our data dashboards, using Management > Saved Objects
and press the Import button.  The dashboard file
is installed at:
@example
@file{@value{DOCDIR}/kibana-dashboards.json}
@end example

@heading Snort, Cyberprobe, Cybermon, Gaffer, ElasticSearch

There is a second configuration which adds Snort and Cyberprobe to the
deployment.  This accesses the host network interface by providing
host network access to the @command{cyberprobe} and @command{snort} containers.
The network interface name is specified in the @file{cyberprobe.cfg}
file for @command{cyberprobe} and the @file{docker-compose-cp-snort.yml}
file for @command{snort} so you will need to edit accordingly.

@example
cd @file{@value{DOCDIR}/}
docker-compose \
  -f @file{@value{DOCDIR}/docker-compose-cp-snort.yml} up
@end example

The configuration results in trigger packet acquisition as soon as
any port 80 or port 11111 data is observed. e.g.

@example
wget -q -O- http://www.example.org/
@end example

@comment ----------------------------------------------------------------------

@node Endace DAG
@chapter Endace DAG

@cindex Endace
@cindex DAG

@command{cyberprobe} includes support for Endace DAG.  This is presently
not distributed.  If you compile @command{cyberprobe} on a host which has
the DAG library (@file{libdag}) installed, it will be detected at the
@command{configure} step.

If DAG support is compiled in, then the DAG devices can be referenced
in the @file{cyberprobe.cfg} file using the prefix @samp{dag} plus the
card number e.g.

@example
  <interfaces>
    <interface name="dag0"/>
  </interfaces>
@end example

To use DAG devices, you need to load DAG firmware, and set all
appropriate card options using @command{dagload} and @command{dagconfig}
prior to starting @command{cyberprobe}.

@comment ----------------------------------------------------------------------

@node Reference
@chapter Reference

@menu
* @command{cyberprobe} invocation::
* @command{cyberprobe} configuration::
* @command{cyberprobe-cli} invocation::
* @command{cyberprobe-cli} commands::
* Output streaming protocols::
* Management protocol::
* @command{cybermon} invocation::
* @command{cybermon} configuration::
* @command{cybermon} example configurations::
* Cybermon JSON message format::
* @command{cybermon-monitor} invocation::
* @command{cybermon-elasticsearch} invocation::
* @command{cybermon-bigquery} invocation::
* @command{cybermon-gaffer} invocation::
* @command{cybermon-cassandra} invocation::
* @command{cybermon-geoip} invocation::
* @command{cybermon-detector} invocation::
* @command{cybermon-dump} invocation::
* @command{cybermon-alert} invocation::
* @command{taxii-client} invocation::
* @command{taxii-sync-json} invocation::
* @command{taxii-server} invocation::
* @command{nhis11-rcvr} invocation::
* @command{etsi-rcvr} invocation::
* ElasticSearch model::
@end menu

@comment ----------------------------------------------------------------------

@node @command{cyberprobe} invocation
@section @command{cyberprobe} invocation

@cindex @command{cyberprobe}, invocation

@command{cyberprobe} is a network monitor which collects packets which match an
IP address list.  The packets collected are streamed using network streaming
protocols.  The IP address match list can be statically conqfigured (in a
configuration file), can be dynamically changed using a management
interface, or can be dynamically changed as a result of snort alerts.
Synopsis:

@example
cyberprobe @var{configuration-file}
@end example

@itemize @bullet

@item
@var{configuration-file} is the name of an XML configuration file. 
See @ref{@command{cyberprobe} configuration}.

@end itemize

@cindex @command{cyberprobe}, configuration

@command{cyberprobe} executes indefinitely - to end the program, a signal should
be sent. e.g.

@example
killall cyberprobe
@end example

@comment ----------------------------------------------------------------------

@node @command{cyberprobe} configuration
@section @command{cyberprobe} configuration
@cindex @command{cyberprobe}, configuration
@cindex @command{cyberprobe}, @code{control}
@cindex @command{cyberprobe}, @code{interfaces}
@cindex @command{cyberprobe}, @code{targets}
@cindex @command{cyberprobe}, @code{endpoints}
@cindex @command{cyberprobe}, @code{snort_alert}
@cindex @code{control}
@cindex @code{interfaces}
@cindex @code{targets}
@cindex @code{endpoints}
@cindex @code{snort_alert}
@cindex IP address matching
@cindex IP address mask
@cindex @code{targets}, address mask

The configuration file is re-read when it changes, and changes are
immediately actioned.

Sample configuration:

@example
<?xml version="1.0" encoding="ISO-8859-1"?>

<configuration>

  <!-- Start a control interface on port 8888. -->
  <control port="8888" username="admin" password="horse_battery_staple">

  <!-- Set of interfaces to use for collection. -->
  <interfaces>

    <!-- filter element is optional.  Can be used to make sure you don't
         sniff the outbound streams. -->
    <interface name="eth0" filter="not port 10001 and not port 10002"/>

    <-- The delay attribute can be used to specify a delay before
           packets are processed.  In seconds. --> 
    <interface name="eth1" delay="0.5"/>

  </interfaces>

  <!-- Statically targeted addresses. -->
  <targets>
    <target address="192.168.1.1" liid="123456"/>
    <target address="192.168.1.2" liid="123981"/>
    <target address="10.2.0.0/16" liid="9123780"/>
    <target address="10.1.1.1" liid="9123780"/>
    <target address="10.1.1.1" liid="9123780"/>
    <target address="10.1.1.0" liid="591875"/>
    <target address="10.1.1.2" liid="492895"/>
    <target address="10.1.1.3" liid="591875"/>
    <target address="10.1.1.4" liid="591875"/>
    <target address="10.1.1.5" liid="591875"/>
    <target address="10.1.1.6" liid="591875"/>
    <target address="10.1.1.7" liid="591875"/>
    <target address="10.1.1.8" liid="591875"/>
    <target address="10.1.1.9" liid="591875"/>
    <target address="10.1.1.10" liid="591875"/>
    <target address="aaaa:bbbb:cccc:dddd::4:5:6"
      class="ipv6" liid="983898"/>
    <target address="aaaa:bbbb:cccc::/48"
      class="ipv6" liid="983800"/>
  </targets>

  <!-- Endpoints for delivery of collected packets. -->
  <endpoints>

    <!-- Send collected packets to monitor1:10001 in NHIS 1.1
         stream. -->
    <endpoint hostname="monitor1" port="10001"
              transport="tcp" type="nhis1.1"/>

    <!-- Send collected packets to monitor2:10002 in ETSI LI
         stream. -->
    <endpoint hostname="monitor2" port="10002"
              transport="tcp" type="etsi"/>

  </endpoints>

  <!-- Set of parameters, primarily used to configure the metadata in
       ETSI LI metadata. -->
  <parameters>

    <!-- Value used for deliveryCountryCode and authorizationCountryCode
         in LI PS PDU. Should be 2-character string. -->
    <parameter key="country" value="DE"/>

    <!-- Value used for operatorIdentifier in LI PS PDU. A string up to
         16 characters. -->
    <parameter key="operator" value="Cyber"/>

    <!-- Value used for networkElementIdentifier in LI PS PDU. String up
         to 16 characters in length. -->
    <parameter key="network_element" value="10.8.2.4"/>

    <!-- Value used for interceptionPointID in LI PS PDU. String up
         to 8 characters in length. -->
    <parameter key="interception_point" value="abcd1234"/>

    <!-- Username values used in IPIRI connection.  Key form is
         "username." plus the LIID -->
    <parameter key="username.123456" value="user01@@example.org"/>
    <parameter key="username.123981" value="user02@@example.org"/>
    <parameter key="username.981235" value="user03@@example.org"/>

    <!-- Parameters in this form are used select the LIID which is used
         when packets are collected on Snort alerts.  Basically, this
         maps the Snort signature ID to a LIID. -->
    <parameter key="snort.1.liid" value="SNORT1"/>
    <parameter key="snort.2.liid" value="SNORT2"/>

   </parameters>

   <!-- Optional element.  Listens for Snort alerts, and dynamically
        targets addresses for 60 seconds. -->
   <!--
   <snort_alert socket="/var/log/snort/snort_alert" duration="60"/>
   -->

</configuration>
@end example

The @code{control} element is optional, if it exists, @command{cyberprobe} runs
a management interface on the specified port. The @code{port},
@code{username} and @code{password} attributes must be specified. See
@ref{Management interface} for how to communicate with that interface.

The @code{interfaces} block defines a set of interfaces to sniff. The
@code{name} attribute is mandatory, the @code{filter} element is optional,
and if specified should describe a BPF (Berkley Packet Filter)
expression. The @code{delay} element can be used to specify, in seconds, the
duration to wait before packets are processed. The delay is specified as a
floating point decimal.

The @code{targets} block defines IP address to match. The
@code{address} attribute defines the IP address with optional mask used for
the address match. If a mask is specified, this describes the subset of the
address which will be used for matching.  For instance, if
@code{192.168.0.0/16} is specified, then a 16-bit mask will be applied, which
makes this a class-B address match.  That is, any address in the
@code{192.168.0.0}-@code{192.168.255.255} range will match.
If no mask is specified, then this is an exact match against a single address.
The @code{liid} attribute defines the LIID which will be applied
if this
particular IP address is detected.

@cindex @code{network} attribute, @file{cyberprobe.cfg}
The optional @code{network} attribute
defines the network (ETSI NetworkElementID), which, if specified,
will be transmitted in the ETSI stream, and delivered as the JSON
@samp{network} element in @command{cybermon} output.
The address must be an IP address, and
not a hostname. The address can be an IPv6 address if the @code{class}
attribute is included, and set to @code{ipv6}.

LIIDs can occur in multiple places in the target block, allowing multiple IP
addresses to match to the same LIID, but the same IP address/mask specifier
should only occur once in the target block.

If subnetwork ranges overlap, the longest prefix match applies.

The @code{liid} and @code{network} can contain template constructs:

@table @samp

@item %i
This is replaced with the IP address which causes a match.

@item %s
This is replaced with the IP address in the target rule - useful if this
is a subnetwork address.

@item %m
This is replaced with the source MAC address in the header of the packet
which causes a match.

@item %v
This is replaced with the VLAN ID in the header of the packet which causes
a match.

@item %%
This is replaced with a literal @code{%}.

@end table

@cindex @code{certificate}, cyberprobe configuration option
@cindex @code{key}, cyberprobe configuration option
@cindex @code{trusted-ca}, cyberprobe configuration option
@cindex TLS
@cindex SSL
@cindex cyberprobe secure delivery
The @code{endpoints} block defines a set of addresses for delivery. The
@code{hostname} and @code{port} attributes should be used to describe the
endpoint address. Type @code{type} attribute should be @code{nhis1.1} or
@code{etsi} to specify which output stream format to use.  The @code{transport}
describe the transport type, which should be @code{tcp} for standard TCP stream,
or @code{tls} for an SSL/TLS stream.  If TLS is invoked, the attributes
@code{certificate}, @code{key} and @code{trusted-ca} should be specified,
with filenames for client certificate, private key, and a trust CA chain.
These should all be in PEM format.

The optional @code{parameters} block defines a set of parameters which are
only used in ETSI delivery. Each parameter element should have a @code{key}
and a @code{value} attribute. The parameter values for @code{country},
@code{operator}, @code{network_element} and @code{interception_point}
describe values which are used in the @code{PSHeader} and @code{IRI}
constructs. The parameters with prefix @code{username.} describe values for
the @code{username} values in the IPIRI construct in ETSI LI. The @code{key}
value is the literal @code{username.} suffixed with the LIID. If such an
entry is present, it is used for the @code{username}. All parameters are
optional, meaningless defaults (e.g. unknown) will be used if not specified.
The @code{etsi-streams} parameter specifies the number of TCP streams which
will be opened for delivery, the default being 12.  This feature potentially
increases throughput, and is useful if the destination is a load-balanced
resource.

@comment ----------------------------------------------------------------------

@node @command{cyberprobe-cli} invocation
@section @command{cyberprobe-cli} invocation

@cindex @command{cyberprobe-cli}, invocation
@cindex Management client

@command{cyberprobe-cli} connects to @command{cyberprobe} on the
management port to allow dynamic administration.  This permits
dynamic management of resources.

@quotation Note
You can end up in a confusing situation if you use both the configuration
file, and the management interface to configure resources.  It is best to
use one or the other.  You can safely use the configuration file
for resources that you don't intend to change through the management interface,
but you shouldn't use both the configuration file and management interface
to change the same resources.
@end quotation

Synopsis:

@example
cyberprobe-cli HOST PORT
@end example

Example:
@example
cyberprobe-cli vpn-host031 8888
@end example

@table @samp

@item HOST
Specifies the hostname or  IP address of the host to connect to.

@item PORT
Specifies the management port number.

@end table

Upon connection, you are prompted to enter a username and password.  Upon
successful authentication, you are then offered a command line prompt for
administration commands.

@comment ----------------------------------------------------------------------

@node @command{cyberprobe-cli} commands
@section @command{cyberprobe-cli} commands

@cindex @command{cyberprobe-cli}, commands
@cindex Management client

The following commands are supported by @command{cyberprobe-cli}:

@table @samp

@item add endpoint HOST PORT TYPE TRANSPORT
Adds a delivery endpoint.
@table @samp
@item HOST
Specifies the delivery host.
@item PORT
Specifies TCP port to deliver to.
@item TYPE
Can be one of @samp{nhis} or @samp{etsi} for delivery protocol.
@item TRANSPORT
Can be one of @samp{tcp} or @samp{tls} for TCP or TLS transports.
@end table

Note: It is not possible to specify the appropriate transport paramters for
TLS delivery using the management interface currently.

@item add interface INTERFACE DELAY [FILTER]
Adds an interface for packet sniffing.
@table @samp
@item INTERFACE
Interface name.
@item DELAY
Delay between packet acquisiton and delivery.  Defaults to zero.
@item FILTER
Optional, species a filter to be applied for positive selection of packets,
in BPF / libpcap format.
@end table

@item add parameter KEY VALUE
Adds a parameter.
@table @samp
@item KEY
Parameter key.
@item VALUE
Parameter value.
@end table

@item add target LIID PROTOCOL ADDRESS
Adds an address target for packet capture.
@table @samp
@item LIID
LIID / device identifier.
@item PROTOCOL
Address protocol, one of @samp{ip4} or @samp{ip6}.
@item ADDRESS
Address value, in IPv4 or IPv6 format, according to the PROTOCOL value.
@end table

@item help
Displays help (not implemented).

@item quit
Causes the client to close the connection and terminate.

@item remove endpoint HOST PORT TYPE TRANSPORT
Removes an endpoint added through the @samp{add endpoint} command.
The HOST, PORT TYPE and TRANSPORT values are the same as for
@samp{add endpoint}.

@item remove interface INTERFACE DELAY [FILTER]
Removes an interface added through the @samp{add interface} command.
The INTERFACE, DELAY and FILTER values are the same as for @samp{add interface}.

@item remove paramter KEY VALUE
Removes a paramter added through the @samp{add parameter} command.
The KEY and VALUE values are the same as for @samp{remove parameter}.

@item remove target PROTOCOL ADDRESS
Removes a target added through the @samp{remove target} command.
The PROTOCOL and ADDRESS values are the same as for @samp{add target}.

@item show endpoints
Displays a table showing endpoints.

@item show interfaces
Displays a table showing interfaces.

@item show parameters
Displays a table showing parameters.

@item show targets
Displays a table showing targets.

@end table

@comment ----------------------------------------------------------------------

@node Output streaming protocols
@section Output streaming protocols

@cindex NHIS 1.1 LI
@cindex ETSI LI
@cindex NHIS 1.1
@cindex ETSI
@cindex ETSI TS 102 232-1
@cindex TS 102 232-1
@cindex LIID

@command{cyberprobe} supports packet output in one of two output formats,
which are both LI formats. LI formats were chosen as they set good, open
standards for streaming packets to a destination. There are also existing
security products such as firewalls, and analysis tools which understand
with these protocols. The two formats are ETSI LI and NHIS 1.1.

@cindex TS 102 232-3
@cindex ETSI TS 102 232-3
@anchor{ETSI LI}
@heading ETSI LI

The first of the formats supported is the ETSI LI format (see ETSI TS 102
232), which is used in Europe and internationally. The protocol is described
using an ASN.1 specification which can be downloaded from the ETSI
web-site. Google can find the standards. The over-arching TS 102 232-1
standard describes the transport, while the TS 102 232-3 standard describes
putting the IP packets in the transport.

Those adverse to the use of ASN.1 technology may prefer the second format.

@cindex TS 101 671
@cindex ETSI TS 101 671
@cindex GLIC
@anchor{NHIS LI}
@heading NHIS LI

NHIS 1.1 which was defined for use in the UK in the 90s, based on GLIC
in ETSI TS 101 671. The protocol is a much simpler header protocol than ETSI
LI, and needs less work to decode.

The standard was available on the internet on the @url{http://gliif.org}
website, but that web-site has recently gone offline.

The bluffers guide to decoding goes...

@itemize

@item
The first 32 bytes after TCP connection are a header. Ignore the first 4
bytes, the latter 28 bytes are the LIID, represented as an ASCII
string. Unused bytes following the LIID are set to zero to pad out to 32
bytes.

@item
Once the start header is sent, the following data consists of IP packets
pre-fixed by a 20 byte header. The only information of note in each 20 byte
header is a 2-byte length field at offset 2 (network byte order). This tells
you the length of the IP packet.

@item
The IP packets are transmitted until the TCP connection closes.  A separate
TCP connection is used for each LIID.

@end itemize

@heading Output semantics

@command{cyberprobe} automatically reconnects to failed destinations, but
the buffering strategy is very simple. When destinations fail, the packets
are buffered in a small queue, but there is limited buffering, so once the
queue fills, packets will start to be dropped. The locking strategy is
simple, so loss of a single endpoint will currently result in data loss to
all endpoints. This may be a problem for operational scenarios where high
data availability is required.

@command{cyberprobe} includes some code to decode the ETSI and NHIS streams,
and also includes two test utilities, @command{etsi-rcvr} and
@command{nhis11-rcvr} which listen on a specified port number, decode the
stream data, and forward in PCAP format on standard output. Example usage
would be:

@example
etsi-rcvr 10001 | tcpdump -n -r-
nhis11-rcvr 10000 | tcpdump -n -r-
@end example

@comment ----------------------------------------------------------------------

@node Management protocol
@section Management protocol
@cindex Management protocol

@heading Overview

The management interface is a simple interface which supports studying and
dynamically changing the cyberprobe configuration: endpoints, targets and
interfaces.

The configuration file specifies a port number, and username and password
for the interface.

The interface is intended to be used programmatically, but it is usable
using a basic telnet. It is a command-response interface, similar in style
to SMTP.

@heading Commands

Commands are sent, one at a time, as a string terminated by a newline. The
following commands are supported:

@table @code

@item auth <user> <password>
Used on initial connection to authenticate.

@item help
Shows help

@item add_interface <iface> <delay> [<filter>]
Starts packet capture from an interface.

@item remove_interface <iface> <delay> [<filter>]
Removes a previously enabled packet capture.

@item interfaces
Lists all interfaces, output is format @code{iface:delay:filter}.

@item add_endpoint <host> <port> <type> <transport>
Adds an endpoint to delivery data to.
where type is one of: @code{etsi} @code{nhis1.1} and
transport is one of: @code{tcp} @code{tls}.
Note that it is not currently possible to specify the configuration required to
get a TLS connection to work. (FIXME).

@item remove_endpoint <host> <port> <type> <transport>
Removes a previously enabled endpoint.
where type is one of: @code{etsi} @code{nhis1.1} and
transport is one of: @code{tcp} @code{tls}.

@item endpoints
Lists endpoints, format is @code{host:port:type:description}.

@item add_target <liid> <class> <address>
@itemx add_target <liid> <class> <address>/<mask>
Adds a new targeted IP address.
where class is one of: @code{ipv4} @code{ipv6}

@item remove_target <liid> <class> <address>
@itemx remove_target <liid> <class> <address>/<mask>
Removes a previously targeted IP address.
where class is one of: @code{ipv4} @code{ipv6}

@item targets
Lists targets, format is @code{liid:class:address/mask}.  The mask
value is always present, even when no mask was present when the target
was added.

@item add_parameter <key> <val>
Adds a new parameter, or changes a parameter value.

@item remove_target <key>
Removes a parameter value.

@item parameters
Lists parameters, format is @code{key:value}.

@end table

In response to a command, one of the following responses may occur:

@itemize

@item
An OK response, which is a @code{200} status code and message. e.g.
@code{200 Endpoint added.}

@item
An error message, which is also a status code and message. e.g.
@code{301 Command not known.}

@end itemize

Error codes always start with 3 or 5. A 3xx error code results from
something which is your fault e.g. procedural or syntactic violation, 5xx
error codes result from errors internal to the system. This is still
probably your fault :) e.g. specifying an interface which doesn't exist.

A response with a body, which is a 201 status code and message. This is
followed by a single line containing a response size in bytes, followed by
the response itself. e.g.

@example
201 Interfaces list follows.
8
eth0:1:
@end example

@heading Example session

For clarity, commands sent to the server are highlighted with @samp{>>}
although this is not present as a prompt or in the protocol dialogue.

@example
>>  interfaces
    330 Authenticate before continuing.
>>  auth user password
    200 Authenticated.
>>  interfaces
    201 Interfaces list follows.
    8
    p4p1:1:
>>  remove_interface p4p1 1
    200 Removed interface.
>>  add_interface p4p1 8
    200 Added interface.
>>  add_target 123456 ipv4 1.2.3.4
    200 Added target.
>>  targets
    201 Targets list follows.
    65
    123456:ipv4:1.2.3.4/32
    123456:ipv4:192.168.1.80/32
    123456:ipv6:aaaa:bbbb:cccc:dddd::4:5:6/128
>>  quit
    200 Tra, then.
@end example

@comment ----------------------------------------------------------------------

@node @command{cybermon} invocation
@section @command{cybermon} invocation

@cindex @command{cybermon}, invocation

@command{cybermon} is a configurable network packet stream analyser.  It is
designed to receive packets from cyberprobe, analyse them and generate
session/transport level events which result in user-configurable
actions. For each event, a call is made to a Lua script which the caller
provides.  Synposes:

@example
cybermon [--help] [--transport TRANSPORT] [--port PORT] [--key KEY]
        [--certificate CERT] [--trusted-ca CHAIN] [--pcap PCAP_FILE]
        [--config CONFIG]
@end example

@itemize @bullet

@item
@var{TRANSPORT}
is either @samp{tcp} or @samp{tls}.  If @samp{tls} is specified, @samp{cybermon}
expects to read data over TLS.  In TLS mode, it is necessary to specify the
key, certificate, and trusted CA files.

@item
@var{PORT}
is a TCP port number.  This form of the command runs as a TCP server
listening for ETSI LI streams.  See @ref{ETSI LI}.

@item
@var{KEY}
specifies a filename for the private key in PEM format.  Only used in TLS mode.

@item
@var{CERT}
specifies a filename for the public certificate in PEM format.
Only used in TLS mode.

@item
@var{CHAIN}
specifies a filename for trusted CA keys in PEM format.  Only used in TLS mode.

@item
@var{PCAP_FILE}
is a PCAP file to read.  This form of the command reads the PCAP file, and
then exits.  If the file is @samp{-}, standard input is read.

@item
@var{CONFIG}
is a Lua configuration file, which specifies the action @command{cybermon}
should take when certain events are observed.  See
@ref{@command{cybermon} configuration}.

@end itemize

@comment ----------------------------------------------------------------------

@node @command{cybermon} configuration
@section @command{cybermon} configuration

@heading Overview

Cybermon is a simple monitoring tool. It receives the ETSI protocol, decodes
the protocols, and makes decoded information available for further handling
which you can specify. The tool is very much a work in progress - it has
limited protocol decode capability at the moment, but there's enough there
to demonstrate the idea.  Usage

Usage is: @code{cybermon <port-number> <config-file>}

You specify a port number to receive data on, and a configuration file
written in Lua. Lua is a simple but powerful scripting language. Here's an
example to help you see how the configuration is used.

@heading Example configuration

The configuration file is there to provide functions which get called when
certain events occur. The calling interface is fairly simple at the moment,
and over time, expect to see a richer interface develop.

To start with, we create the structure of the configuration file. Call it
something with a @code{.lua} extension e.g. @code{config.lua} so that your
editor knows how to indent the code. The basic structure is a module with a
number of functions:

@example
local observer = @{@}

-- This function is called when a trigger events starts collection of an
-- attacker.
-- e.device = the trigger device
-- e.addr = trigger address
observer.trigger_up = function(e)
end

-- This function is called when an attacker goes off the air
-- e.device = the trigger device.
observer.trigger_down = function(e)
end

-- This function is called when a stream-orientated connection is made
-- (e.g. TCP).
-- e.context = protocol context
observer.connection_up = function(e)
end

-- This function is called when a stream-orientated connection is closed
-- e.context = protocol context
observer.connection_down = function(e)
end

-- This function is called when a datagram is observed, but the protocol
-- is not recognised.
-- e.context = protocol context
-- e.data = payload
observer.unrecognised_datagram = function(e)
end

-- This function is called when stream data  is observed, but the
-- protocol is not recognised.
-- e.context = protocol context
-- e.data = payload
observer.unrecognised_stream = function(e)
end

-- This function is called when an ICMP message is observed.
-- e.context = protocol context
-- e.type = ICMP type
-- e.code = ICMP code
-- e.data = payload
observer.icmp = function(e)
end

-- This function is called when an IMAP message is observed.
-- e.context = protocol context
-- e.data = payload
observer.imap = function(e)
end

-- This function is called when an IMAP SSL message is observed.
-- e.context = protocol context
-- e.data = payload
observer.imap_ssl = function(e)
end

-- This function is called when a POP3 message is observed.
-- e.context = protocol context
-- e.data = payload
observer.pop3 = function(e)
end

-- This function is called when a POP3 SSL message is observed.
-- e.context = protocol context
-- e.data = payload
observer.pop3_ssl = function(e)
end

-- This function is called when an HTTP request is observed.
-- e.context = protocol context
-- e.method = HTTP method
-- e.url = HTTP URL
-- e.header = HTTP header, an associative array
-- e.body = body payload
observer.http_request = function(e)
end

-- This function is called when an HTTP response is observed.
-- e.context = protocol context
-- e.code = HTTP code
-- e.status = HTTP status
-- e.header = HTTP header, an associative array
-- e.url = HTTP URL
-- e.body = HTTP response body
observer.http_response = function(e)
end

-- This function is called when a SIP request message is observed.
-- e.context = protocol context
-- e.method = HTTP method
-- e.from = SIP originator address
-- e.to = SIP destination address
-- e.data = SIP payload
observer.sip_request = function(e)
end

-- This function is called when a SIP response message is observed.
-- e.context = protocol context
-- e.code = SIP response code
-- e.status = SIP response status
-- e.from = SIP originator address
-- e.to = SIP destination address
-- e.data = SIP payload
observer.sip_response = function(e)
end

-- This function is called when a SIP SSL message is observed.
-- e.context = protocol context
-- e.data = payload
observer.sip_ssl = function(e)
end

-- This function is called when an SMTP command is observed.
-- e.context = protocol context
-- e.command = SMTP command
observer.smtp_command = function(e)
end

-- This function is called when an SMTP response is observed.
-- e.context = protocol context
-- e.status = SMTP response status
-- e.text = response text, an array of lines
observer.smtp_response = function(e)
end

-- This function is called when an SMTP response is observed.
-- e.context = protocol context
-- e.from = SMTP originator addresses, a string
-- e.to = SMTP recipients, an array of strings
observer.smtp_data = function(e)
end

-- This function is called when a DNS message is observed.
-- e.context = protocol context
-- e.header = DNS header
-- e.queries = DNS queries
-- e.answers = DNS answers
-- e.auth = DNS authentication records
-- e.add = DNS additional records
observer.dns_message = function(e)
end

-- This function is called when an FTP command is observed.
-- e.context = protocol context
-- e.command = FTP command
observer.ftp_command = function(e)
end

-- This function is called when an FTP response is observed.
-- e.context = protocol context
-- e.status = FTP response status
-- e.text = response text, an array of lines
observer.ftp_response = function(e)
end

-- This function is called when an NTP timestamp message is observed.
-- e.context = protocol context
-- e.header = NTP header
-- e.timestamp = NTP timestamp
observer.ntp_timestamp_message = function(e)
end

-- This function is called when an NTP control message is observed.
-- e.context = protocol context
-- e.header = NTP header
-- e.control = NTP control info
observer.ntp_control_message = function(e)
end

-- This function is called when an NTP private message is observed.
-- e.context = protocol context
-- e.header = NTP header
-- e.private = NTP private info
observer.ntp_private_message = function(e)
end

-- Return the table
return observer

@end example

@cindex LUA events
@cindex @code{cybermon} events
@heading LUA event calls

The configuration file is expected to provide the following functions, which
are called in response to @command{cybermon} events.

@table @code

@item trigger_up(e)

Called when an attacker is seen coming on-stream.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item device
describes the device ID

@item address
contains the triggering IP address in string form.

@end table

@item trigger_down(e)
Called when an attacker is seen going off-stream.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item device
describes the device ID

@end table

@item connection_up(e)
Called when a stream-based connection (e.g. TCP) is made.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@end table

@item connection_down(e)
Similar to @code{connection_up}, called when a connection closes.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@end table

@item icmp(e)
Called when an ICMP message is detected.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item type
ICMP type value

@item code
ICMP code value

@end table

@item http_request(e)
Called when an HTTP request is observed.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item method
HTTP method

@item url
HTTP URL (derived from host and path).

@item header
HTTP header values in a Lua associative array.

@item body
HTTP request body, if one exists.

@end table

@item http_response(e)
Called when an HTTP response is observed.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item code
HTTP response code

@item status
HTTP response status

@item header
HTTP response header, a Lua associative array.

@item body
HTTP response body.

@end table

@item smtp_command(e)
Called when an SMTP command is observed i.e. a single line message going to
the server from a client.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item command
the SMTP command

@end table

@item smtp_response(e)
Called when an SMTP response is observed.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item status
the SMTP status value e.g. @code{200}

@item text
SMTP human-readable response text, an array of strings

@end table

@item smtp_data(e)
Called when an SMTP payload is observed i.e. the body of text following the
DATA command. To aid processing, the SMTP protocol processor assembles
information from other commands.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information

@item from
contains the email From address described in the MAIL FROM command.

@item to
a list of addresses contained in all RCPT TO commands.  An array of strings.

@item data
contains the email body - it will be an RFC822
payload.

@end table

@item ftp_command(e)
Called when an FTP command is observed i.e. a single line message going to
the server from a client.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item command
contains the command string.

@end table

@item ftp_response(e)
Called when an FTP response is observed. That is, status going from server
to client following a command.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item status
FTP status code e.g. 200.

@item text
contains the response text,
described as a list of strings. Responses may occur over a number of lines,
hence the parameter is a list: For single-line responses, there is only a
single item in the list.

@end table

@item dns_message(e)
Called when a DNS message is observed.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item header
describes the DNS header

@item query
the DNS queries

@item answer
contains the answers in a response message

@item auth
DNS nameserver authority descriptions

@item add
provides additional DNS records

@end table

@item ntp_timestamp_message(e)
Called when a NTP timestamp message is observed.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item header
the NTP header

@item timestamp
contains the specific timestamp information

@end table

@item ntp_control_message(e)
Called when a NTP control message is observed.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item header
the NTP header

@item control
specific NTP control information.

@end table

@item ntp_private_message(e)
Called when a NTP control message is observed.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item header
the NTP header

@item private
specific NTP private information.

@end table

@item unrecognised_datagram(e)
Called when a datagram is received using a protocol which isn't
recognised.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item data
the payload.

@end table

@item unrecognised_stream(e)
Called when connection-orientated data is received using a protocol which
isn't recognised.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item data
the payload.

@end table

@item imap(e)
Called when an IMAP message is detected - this is currently a port number
detection.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item data
the payload.

@end table

@item imap_ssl(e)
Called when an IMAP SSL message is detected. This is currently a port number
detection.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item data
the payload.

@end table

@item pop3(e)
Called when a POP3 message is detected.  This is currently
a port number detection.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item data
the payload.

@end table

@item pop3_ssl(e)
Called when a POP3 SSL message is detected. This is currently a port number
detection.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item data
the payload.

@end table

@item sip_request(e)
Called when a SIP request is observed.

A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.


@item from
SIP originator

@item to
SIP destination

@item method
SIP method

@item data
the payload.

@end table

@item sip_response(e)
Called when a SIP request is observed.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item code
SIP response code

@item status
SIP response status

@item from
SIP originator

@item to
SIP destination

@item data
the payload.

@end table

@item sip_ssl(e)
Called when a SIP SSL message is detected. This is currently a port number
detection.
A single parameter is passed, a table containing the following values:

@table @code

@item time
time of event in format @code{YYYYMMDDTHHMMSS.sssZ}

@item context
a LUA userdata variable which can't be access directly, but can
be used with the functions described below to access further information
from @command{cybermon}.

@item data
the payload.

@end table

@end table

@cindex @code{context} object
@cindex @code{cybermon} @code{context} object
@heading Context object

From the LUA code there, the @code{context} variable has a number of method
functions which can be called:

@table @code

@item context:get_type()
Returns the protocol type of the context e.g. @code{http}, @code{tcp}, @code{udp}, @code{dns}, @code{ip4}

@item context:get_parent()

Returns the parent context relating to a context. This can be used to travel
"up" the protocol stack. For example, call get_parent on a TCP context will
return the IP context.

@item context:get_src_addr()
Returns the source address relating to a context. Returns two string
variables: the first is the address class e.g. @code{ipv4}, the second is the
address value e.g. @code{1.2.3.4}.

@item context:get_dest_addr()
Returns the destination address relating to a context. Returns two string
variables: the first is the address class e.g. @code{ipv4}, the second is the
address value e.g. @code{1.2.3.4}.

@item context:get_reverse()
Returns the context relating to the "other side" of a communication, but
only if this has been identified. On an HTTP response, @code{get_reverse}
will return the HTTP request. In the @code{http_request} function you will
not be able to use @code{get_reverse} to find the HTTP response because the
response does not exist at the point the request is identified.

@item context:get_id()
Returns a context's unique ID. Can be useful for tracking, or can be used as
index into your own LUA structures to associate information with contexts.

@item context:describe_src()
Returns a human readable description of the protocol stack using source
addresses.

@item context:describe_dest()
Returns a human readable description of the protocol stack using source
addresses.

@item context:get_liid()
Returns the trigger ID associated with a "target".

@item context:get_network_info()
@cindex @code{network} attribute, @file{cyberprobe.cfg}
Returns three variables: the network name (from ETSI NetworkElementID),
the source and destination network addresses (IP addresses) for this data.
These are in normal IP address string format.  Network name is
the empty string, if not provided in the input stream.
See @ref{@command{cyberprobe} configuration} for specifying the
network.

@item context:get_trigger_info()
Returns the IP address which triggered this collection, if known. If not,
@code{0.0.0.0}x is returned. This is in normal IP address string format.

@item context:forge_tcp_reset()
Creates a TCP reset packet and directs it at the source address associated
with this context. Must have TCP protocol present in the stack.

@item context:forge_dns_response(header, queries, answers, add)
Creates a DNS message and directs it at the source
address associated with this context. The provided parameters are used as
protocol data in the DNS encoder.

@end table

@comment ----------------------------------------------------------------------

@node @command{cybermon} example configurations
@section @command{cybermon} example configurations

@cindex @command{cybermon}, example configurations
@cindex @command{cybermon}, configuration
@heading Example configuration files

@table @file

@item forge-dns.lua

Example Lua script, spots DNS queries for @samp{example.org}, and responds
with made-up IP addresses.

@item forge-reset.lua

Example script, spots TCP port 22 sessions (which is the port number normally
used for SSH sessions).  If detected, a TCP reset is forged.

@item hexdump.lua

Like @file{monitor.lua}, but adds a hex-dump of event payloads to the output.

@item monitor.lua

For each Lua event, outputs a plain text summary of the output on standard
output.

@item zeromq.lua

@cindex ZeroMQ
@cindex Cybermon JSON message format
@cindex publish/subscribe
@cindex pub/sub
@cindex JSON

For each Lua event, a JSON record is formatted and published to a ZeroMQ
queue on port 5555.  See @ref{Cybermon JSON message format}.

@item amqp-topic.lua

@cindex AMQP
@cindex RabbitMQ
@cindex Cybermon JSON message format
@cindex publish/subscribe
@cindex pub/sub
@cindex JSON

For each Lua event, a JSON record is formatted and published to a RabbitMQ
broker.  See @ref{Cybermon JSON message format}.  Environment variables
@samp{AMQP_BROKER}, @samp{AMQP_EXCHANGE}, @samp{AMQP_ROUTING_KEY} can be
used to tailor delivery.

@item redis.lua

@cindex Redis
@cindex Cybermon JSON message format
@cindex queue delivery using Redis
@cindex JSON

For each Lua event, a JSON record is formatted and RPUSH'd to a Redis server
defiend by the @code{REDIS_SERVER} environment variable which should be in
@code{HOST:PORT} form.
Each message is JSON format, see @ref{Cybermon JSON message format}.

@item json.lua

@cindex Cybermon JSON message format
@cindex JSON

For each Lua event, a JSON record is formatted and delivered to standard
outut.
Each message is JSON format, see @ref{Cybermon JSON message format}.

@item quiet.lua

Does nothing.  This is an empty code shell, and a good template to write
your own event handler.

@end table

@heading Utilities

The @file{@value{SYSCONFDIR}/cyberprobe/util} directory contains some Lua
utilities which can be used by other Lua configuration files.  They can be
loaded as modules e.g.

@example
local addr = require("util.addresses")
@end example

The utilities are:

@table @file

@item addresses.lua
Some @code{cybermon} address handling functions.

@item json.lua
The real JSON formatting is done here.

@end table

@comment ----------------------------------------------------------------------

@node Cybermon JSON message format
@section Cybermon JSON message format

@cindex ZeroMQ
@cindex RabbitMQ
@cindex AMQP
@cindex Redis
@cindex Cybermon JSON message format
@cindex publish/subscribe
@cindex pub/sub
@cindex JSON

Cybermon's @samp{amqp-topic.lua}, @samp{zeromq.lua} and @samp{redis.lua}
configuration files
transmit messages in JSON format.  Each message is a JSON object
with the following fields:

@table @samp

@item id
Unique ID for the event: UUID format
(e.g. 3c55d830-8d99-48a1-c8cd-ca77514a6d10).

@item device
Device identifier / LIID.

@item network
@cindex @code{network} attribute, @file{cyberprobe.cfg}
Network identifier, if ETSI stream delivery is used, and the
@code{network} identifier is used in @file{cyberprobe.cfg}.
See @ref{@command{cyberprobe} configuration}

@item action
The event type.  One of:
@table @samp
@item connected_up
Records the creation of a stream-orientated connection (currently, only TCP).
This event is created for all connections whether the protocol is
recognised or not.
@item connected_down
Records the closing of a stream-orientated connection (currently, only TCP).
This event is created for all connections whether the protocol is
recognised or not.
@item unrecognised_stream
Records the sending of a PDU on a connection-less transport (currently, only
UDP) whose protocol has not been recognised.
@item unrecognised_datagram
Records the sending of a PDU on a connection-less transport (currently, only
UDP) whose protocol has not been recognised.
@item http_request
Records the sending of an HTTP request.
@item http_response
Records the sending of an HTTP response.
@item dns_message
Records the sending of a DNS message (request and response).
@item icmp
Records the sending of an ICMP message.
@item smtp_command
Records the sending of an SMTP command.  This is a message from client
to server.  Data commands are not recorded with this event - there is an
@samp{smtp_data} event which records this.
@item smtp_response
Records the sending of a response to an SMTP command.  This is a status
message from server to client.
@item smtp_data
Records an SMTP data transaction, including the full SMTP data payload
(essentially an email).
@item ftp_command
Records an FTP command (client to server).
@item ftp_response
Records an FTP response (server to client).
@item ntp_message
Records the sending of a NTP message, including the NTP hdr (mode, version, leap second indicator)
@item imap
Records the presence of IMAP data.
@item imap_ssl
Records the presence of IMAP SSL data.
@item pop3
Records the presence of POP.3 data.
@item pop3_ssl
Records the presence of POP3 SSL data.
@item sip_request
Records the sending of a SIP request.
@item sip_response
Records the sending of a SIP response.
@item sip_ssl
Records the presence of SIP SSL data.
@end table

@item url
The URL identified in any protocol which supports URL request/response e.g.
HTTP.

@item src
A list of source protocol addresses travelling up the stack.
Strings are of the form
@code{protocol:address} or @code{protocol}.  Example protocol types are:
@code{tcp}, @code{udp} and @code{ipv4}.

@item dest
A list of source protocol addresses travelling up the stack.
Strings are of the form
@code{protocol:address} or @code{protocol}.  Example protocol types are:
@code{tcp}, @code{udp} and @code{ipv4}.

@item time
Time of the event in the form @code{2017-04-24T12:34:24.341Z}.


@item dns_message
Emitted when @code{action} is @code{dns_message}.
@code{dns_message} is itself a
JSON object containing the following fields:

@table @samp
@item query
Describes DNS query records in @samp{dns_message} actions. Is a list
of objects with @samp{name}, @samp{type} and @samp{class} fields containing
strings for name, type and class.

@item answer
Describes DNS answer records in @samp{dns_message} actions.  Is a list
of objects with @samp{name}, @samp{type} and @samp{class} and @samp{address}
fields containing strings for name, type and class and IP address.

@item type
DNS message type, one of @samp{query} or @samp{response}.

@end table


@item unrecognised_datagram
Emitted when @code{action} is @code{unrecognised_datagram}.
The value is a JSON object ontaining the following fields:

@table @samp

@item datagram
The datagram body, Base64 encoded.

@end table


@item unrecognised_stream
Emitted when @code{action} is @code{unrecognised_stream}. 
The value is a JSON object ontaining the following fields:

@table @samp

@item payload
The datagram body, Base64 encoded.

@end table


@item icmp
Emitted when @code{action} is @code{icmp}.
The value is a JSON object
ontaining the following fields:

@table @samp

@item type
ICMP type field.

@item code
ICMP code field.

@item data
Raw ICMP payload, Base64 encoded.

@end table


@item http_request
Emitted when @code{action} is @code{http_request}.
The value is a JSON object
ontaining the following fields:

@table @samp

@item method
HTTP method.

@item header
An object containing key/value pairs for HTTP header.

@item body
HTTP body, Base64 encoded.

@end table


@item http_response
Emitted when @code{action} is @code{http_response}.
The value is a JSON object
ontaining the following fields:

@table @samp

@item code
HTTP code field e.g. 200.

@item status
HTTP status field e.g. OK.

@item header
An object containing key/value pairs for HTTP header.

@item body
HTTP body, Base64 encoded.

@end table


@item sip_request
Emitted when @code{action} is @code{sip_request}. The value is a JSON object
containing the following fields:

@table @samp

@item method
SIP method e.g. INVITE.

@item from
The SIP caller address.

@item to
The SIP callee address.

@item data
SIP message body, base64-encoded.

@end table


@item sip_response
Emitted when @code{action} is @code{sip_response}. The value is a JSON object
containing the following fields:

@table @samp

@item code
SIP response code.

@item status
SIP response status.

@item from
The SIP caller address.

@item to
The SIP callee address.

@item data
SIP message body, base64-encoded.

@end table


@item sip_ssl
Emitted when @code{action} is @code{sip_ssl}.The value is a JSON object
containing the following fields:

@table @samp

@item payload
The message payload, base64-encoded.

@end table


@item imap
Emitted when @code{action} is @code{imap}.The value is a JSON object
containing the following fields:

@table @samp

@item payload
The message payload, base64-encoded.

@end table


@item imap_ssl
Emitted when @code{action} is @code{imap_ssl}.The value is a JSON object
containing the following fields:

@table @samp

@item payload
The message payload, base64-encoded.

@end table


@item pop3
Emitted when @code{action} is @code{pop3}.The value is a JSON object
containing the following fields:

@table @samp

@item payload
The message payload, base64-encoded.

@end table


@item pop3_ssl
Emitted when @code{action} is @code{pop3_ssl}.The value is a JSON object
containing the following fields:

@table @samp

@item payload
The message payload, base64-encoded.

@end table


@item ntp_timestamp
Emitted when @code{action} is @code{ntp_timestamp}. The value is a JSON object
containing the following fields:

@table @samp

@item version
NTP header version field.

@item mode
NTP header mode field.

@end table


@item ntp_control
Emitted when @code{action} is @code{ntp_control}. The value is a JSON object
containing the following fields:

@table @samp

@item version
NTP header version field.

@item mode
NTP header mode field.

@end table


@item ntp_private
Emitted when @code{action} is @code{ntp_private}. The value is a JSON object
containing the following fields:

@table @samp

@item version
NTP header version field.

@item mode
NTP header mode field.

@end table


@item ftp_command
Emitted when @code{action} is @code{ftp_command}.The value is a JSON object
containing the following fields:

@table @samp

@item command
The FTP command e.g. PASV.

@end table


@item ftp_response
Emitted when @code{action} is @code{ftp_response}.The value is a JSON object
containing the following fields:

@table @samp

@item status
The FTP response status e.g. 200.

@item text
The FTP response human-readable text.

@end table


@item smtp_command
Emitted when @code{action} is @code{smtp_response}.The value is a JSON object
containing the following fields:

@table @samp

@item command
The SMTP command.

@end table


@item smtp_response
Emitted when @code{action} is @code{smtp_response}.The value is a JSON object
containing the following fields:

@table @samp

@item status
The SMTP response status.

@item text
The SMTP response human-readable text.

@end table


@item smtp_data
Emitted when @code{action} is @code{smtp_data}.The value is a JSON object
containing the following fields:

@table @samp

@item from
The value of the SMTP MAIL FROM field, a string.

@item to
A list of strings containing all SMTP RCPT TO field values.

@item body
The SMTP email body.

@end table


@item location
@cindex GeoIP
@cindex @command{cybermon-geoip}
Not emitted by @command{cybermon}, but can be added to the message by
@command{cybermon-geoip}.  See @ref{@command{cybermon-geoip} invocation}.

The @code{location} object contains potentially two child-objects:
@code{src} and @code{dest}.  Both @code{src} and @code{dest} may contain the
following fields, if the information is known:

@table @samp

@item city
Name of the city from the GeoIP database.

@item iso
Country ISO code, 2 characters.

@item country
Country name.

@item latitude
Latitude, degrees north of the equator.

@item longitude
Longitude, degrees east of Greenwich.

@end table


@item indicators
@cindex IOC
@cindex Indicator of compromise
@cindex @command{cybermon-detector}
Not emitted by @command{cybermon}, but can be added to the message by
@command{cybermon-detector}.  See @ref{@command{cybermon-detector} invocation}.

The @code{indicators} object is an array of IOC hits, if any have been
detected.  Each array element is an object with the following fields:

@table @samp

@item id
IOC identifier.

@item type
IOC type, one of: @code{ipv4}, @code{hostname}, @code{tcp}, @code{udp},
@code{hostname}, @code{email}, @code{url}.

@item value
IOC hit value.

@item description
Human-readable text describing the IOC.

@end table

@end table

@comment ----------------------------------------------------------------------

@node @command{cybermon-monitor} invocation
@section @command{cybermon-monitor} invocation

@cindex @command{cybermon-monitor}, invocation

@command{cybermon-monitor} subscribes to a RabbitMQ pub/sub queue for
@command{cybermon}
events, and upon receipt of events, formats them for output in a human-readable
manner.

Synopsis:

@example
cybermon-monitor [BINDING]
@end example

Example:
@example
cybermon-monitor
cybermon-monitor cyberprobe
@end example

@table @samp

@item BINDING
Specifies the RabbitMQ pub/sub queue to connect to.  If not specified, defaults
to @samp{cyberprobe}.

@end table

@comment ----------------------------------------------------------------------

@node @command{cybermon-elasticsearch} invocation
@section @command{cybermon-elasticsearch} invocation

@cindex @command{cybermon-elasticsearch}, invocation

@command{cybermon-elasticsearch} subscribes to a RabbitMQ pub/sub queue for
@command{cybermon}
events, and upon receipt of events, formats them for delivery to an
ElasticSearch store.

Synopsis:

@example
cybermon-elasticsearch [BINDING [ELASTICSEARCH-URL] ]
@end example

Example:
@example
cybermon-elasticsearch
cybermon-elasticsearch ioc http://elastic-store:9200/
@end example

@table @samp

@item BINDING
Specifies the RabbitMQ pub/sub queue to connect to.  If not specified, defaults
to @samp{ioc}.

@item ELASTICSEARCH-URL
Specifies the base URL for ElasticSearch.  If not specified, defaults
to @samp{http://localhost:9200}.

@end table

@comment ----------------------------------------------------------------------

@node @command{cybermon-bigquery} invocation
@section @command{cybermon-bigquery} invocation

@cindex @command{cybermon-bigquery}, invocation

@command{cybermon-bigquery} subscribes to a RabbitMQ pub/sub queue for
@command{cybermon}
events, and upon receipt of events, formats them for delivery to a Google
BigQuery table.

Synopsis:

@example
cybermon-bigquery [BINDING [KEY-FILE [PROJECT [DATASET [TABLE] ] ] ] ]
@end example

Example:
@example
cybermon-bigquery
cybermon-bigquery ioc /priv.json
@end example

@table @samp

@item BINDING
Specifies the RabbitMQ pub/sub queue to connect to.  If not specified, defaults
to @samp{ioc}.

@item KEY-FILE
Specifies the path to a Google cloud key file in 'private JSON' format.
If not specified, defaults
to @file{/etc/cyberprobe/private.json}.

@item PROJECT
Specifies the Google Cloud project ID to use.  Defaults to the project ID
specified in the private JSON key file.

@item DATASET
Specifies the BigQuery data set, defaults to @samp{cyberprobe}.  You need to
create this dataset, it is not created for you.

@item TABLE
Specifies the BigQuery table within the dataset.  This is created if it does
not already exist.  Don't try to create this yourself, if you use the wrong
schema, data won't load correctly.

@end table

@comment ----------------------------------------------------------------------

@node @command{cybermon-gaffer} invocation
@section @command{cybermon-gaffer} invocation

@cindex @command{cybermon-gaffer}, invocation
@cindex Gaffer
@cindex Graph store

@command{cybermon-gaffer} subscribes to a RabbitMQ pub/sub queue for
@command{cybermon}
events, and upon receipt of events, formats them for delivery to a
Gaffer store.  The format used is intended to allow Gaffer to be used
as an RDF store with SPARQL query.  To query and visualise the data stored in
Gaffer, see @url{https://github.com/cybermaggedon/gaffer-tools}.
To get started with Gaffer quickly, a docker container for development
can be found at
@url{https://docker.io/cybermaggedon/gaffer}.

Synopsis:

@example
cybermon-gaffer [BINDING [GAFFER-URL] ]
@end example

Example:
@example
cybermon-gaffer
cybermon-gaffer ioc \
    http://gaffer-store:8080/rest/v1
@end example

@table @samp

@item BINDING
Specifies the RabbitMQ pub/sub queue to connect to.  If not specified, defaults
to @samp{ioc}.

@item GAFFER-URL
Specifies the base URL for Gaffer.  If not specified, defaults
to @samp{http://gaffer:8080/example-rest/v1}.

@end table

@comment ----------------------------------------------------------------------

@node @command{cybermon-cassandra} invocation
@section @command{cybermon-cassandra} invocation

@cindex @command{cybermon-cassandra}, invocation
@cindex Apache Cassandra
@cindex Cassandra
@cindex Graph store

@command{cybermon-cassandra} subscribes to a RabbitMQ pub/sub queue for
@command{cybermon}
events, and upon receipt of events, formats them for delivery to a
Cassandra store.  The format used is intended to allow Cassandra to be used
as an RDF store with SPARQL query.  To query and visualise the data stored in
Cassandra, see @url{https://github.com/cybermaggedon/cassandra-redland}.

Synopsis:

@example
cybermon-cassandra [BINDING [CASSANDRA-HOSTS] ]
@end example

Example:
@example
cybermon-cassandra
cybermon-cassandra ioc cassandra1,cassandra2
@end example

@table @samp

@item BINDING
Specifies the RabbitMQ pub/sub queue to connect to.  If not specified, defaults
to @samp{ioc}.

@item CASSANDRA-HOSTS
Specifies a comma-separated list of Cassandra store hosts to contact.
If not specified, defaults
to @samp{localhost}.

@end table

@comment ----------------------------------------------------------------------

@node @command{cybermon-geoip} invocation
@section @command{cybermon-geoip} invocation

@cindex @command{cybermon-geoip}, invocation
@cindex GeoIP

@command{cybermon-geoip} subscribes to a RabbitMQ pub/sub queue for
@command{cybermon} events, adds location information from GeoIP, and
re-publishes the elaborated events.  This effectively creates a processing
chain.  The event subscription and publishing events should be different in
order to avoid creating an infinite loop.

Synopsis:

@example
cybermon-geoip [BINDING [PUBLICATION] ]
@end example

Example:
@example
cybermon-geoip
cybermon-geoip cyberprobe geo
@end example

@table @samp

@item BINDING
Specifies the RabbitMQ pub/sub queue to connect to.  If not specified, defaults
to @samp{cyberprobe}.

@item PUBLICATION
Specifies the RabbitMQ pub/sub queue to publish to.  If not specified, defaults
to @samp{geo}.

@end table

@comment ----------------------------------------------------------------------

@node @command{cybermon-detector} invocation
@section @command{cybermon-detector} invocation

@cindex @command{cybermon-detector}, invocation
@cindex STIX
@cindex IOC
@cindex Indicator of compromise

@command{cybermon-detector} subscribes to a RabbitMQ pub/sub queue for
@command{cybermon} events, inspects them for IOCs, and adds detection
information if IOCs are observed before re-publishing
the elaborated events.  This effectively creates a processing
chain.  The event subscription and publishing events should be different in
order to avoid creating an infinite loop.

Synopsis:

@example
cybermon-detector [BINDING [PUBLICATION] ]
@end example

Example:
@example
cybermon-detector
cybermon-detector geo ioc
@end example

@table @samp

@item BINDING
Specifies the RabbitMQ pub/sub queue to connect to.  If not specified, defaults
to @samp{geo}.

@item PUBLICATION
Specifies the RabbitMQ pub/sub queue to publish to.  If not specified, defaults
to @samp{ioc}.

@end table

@comment ----------------------------------------------------------------------

@node @command{cybermon-dump} invocation
@section @command{cybermon-dump} invocation

@cindex @command{cybermon-dump}, invocation
@cindex JSON
@cindex Cybermon JSON message format

@command{cybermon-dump} subscribes to a RabbitMQ pub/sub queue for
@command{cybermon} events, and dumps the raw JSON to standard output.

Synopsis:

@example
cybermon-dump [BINDING]
@end example

Example:
@example
cybermon-dump
cybermon-dump cyberprobe
@end example

@table @samp

@item BINDING
Specifies the RabbitMQ pub/sub queue to connect to.  If not specified, defaults
to @samp{cyberprobe}.

@end table

@comment ----------------------------------------------------------------------

@node @command{cybermon-alert} invocation
@section @command{cybermon-alert} invocation

@cindex @command{cybermon-alert}, invocation
@cindex Alert

@command{cybermon-alert} subscribes to a RabbitMQ pub/sub queue for
@command{cybermon} events, and outputs a human-readable message
when an IOC hits.

Synopsis:

@example
cybermon-alert [BINDING]
@end example

Example:
@example
cybermon-alert
cybermon-alert ioc
@end example

@table @samp

@item BINDING
Specifies the RabbitMQ pub/sub queue to connect to.  If not specified, defaults
to @samp{ioc}.

@end table

@comment ----------------------------------------------------------------------

@node @command{taxii-client} invocation
@section @command{taxii-client} invocation

@cindex @command{taxii-client}, invocation

@command{taxii-client} provides a means to connect with a TAXII compliant
server to acquire cyber threat information.  TAXII/STIX implementation
is experimental and incomplete.

See
@url{https://taxii.mitre.org/} for more information on TAXII and STIX.
Synopsis:

@example
taxii-client [-h] [--host HOST] [--port PORT] [--path PATH]
        [--collection COLLECTION] [--begin_timestamp BEGIN_TS]
        [--end_timestamp END_TS] [--discovery] [--poll]
        [--collection_information] [--subscribe] [--action ACT]
        [--query QUERY] [--subs-id SUBSCRIPTION_ID]
        [--inbox INBOX]
@end example

Example:
@example
taxii-client -h taxii.com --poll
@end example

@table @samp

@item -h
@itemx --help
Shows command line usage.

@item --host @var{HOST}
Specifies host to connect to.

@item --port @var{PORT}
Specifies port number of the TAXII service.

@item --path @var{PATH}
Specifies the URI of the service.  Default is @samp{/}.

@item --collection @var{COLLECTION}
Specifies the TAXII collection to use.  Default is @samp{default}.

@item --begin_timestamp @var{BEGIN}
Specifies the TAXII collection to use.  Default is @samp{default}.

@item --end_timestamp @var{END}
Specifies the TAXII collection to use.  Default is @samp{default}.

@item --discovery
Invokes a TAXII discovery action.

@item --poll
Invokes a TAXII poll action.

@item --collection_information
Invokes a collection information action.

@item --subscribe
Invokes a TAXII subscribe action.

@item --action @var{ACT}
Specieis the subscription action to perform.

@item --query @var{QUERY}
Specifies the query to use for an inbox or poll action.  Query takes the
form: @samp{type:value}.  Type can be one of:

@table @samp

@item address
CybOX address object value e.g. @samp{address:1.2.3.4}

@item addresstype
CybOX address object type e.g. @samp{addresstype:e-mail}

@item domainname
CybOX DNS name

@item port
TCP/UDP port number e.g. @samp{port:11111}

@item hash
File object hash value.

@item id
Object ID.

@item source
Object source identifier.

@end table

Multiple query values may be specified in which case they are combined with
a logical AND.

@item --subs-id @var{SUBS-ID}
Specifies the subscription ID for a subscription operation.

@item --inbox @var{INBOX}
Specifies the inbox destination for subscriptions.  The default value is
@code{http://localhost:8888/}.

@end table

Begin/end timestamps take the following form:
@example
YYYY-MM-DDTHH:MM:SS.ssssss+/-hh:mm
@end example

@comment ----------------------------------------------------------------------

@node @command{taxii-sync-json} invocation
@section @command{taxii-sync-json} invocation

@cindex @command{taxii-sync-json}, invocation

@command{taxii-sync-json} provides a means to connect with a TAXII compliant
server to acquire cyber threat information.  @command{taxii-sync-json}
uses a TAXII poll request, and reformats all STIX information into a single
JSON file which is written to the current directory.  This JSON form is
intended to be used with @command{cybermon-detector}.
See @ref{@command{cybermon-detector} invocation}.

TAXII/STIX implementation is experimental and incomplete.

See
@url{https://taxii.mitre.org/} for more information on TAXII and STIX.
Synopsis:

@example
taxii-sync-json [-h] [--host HOST] [--port PORT] [--path PATH]
        [--collection COLLECTION] [--begin_timestamp BEGIN_TS]
        [--end_timestamp END_TS]
@end example

Example:
@example
taxii-sync-json -h taxii.com
@end example

@table @samp

@item -h
@itemx --help
Shows command line usage.

@item --host @var{HOST}
Specifies host to connect to.

@item --port @var{PORT}
Specifies port number of the TAXII service.

@item --path @var{PATH}
Specifies the URI of the service.  Default is @samp{/}.

@item --collection @var{COLLECTION}
Specifies the TAXII collection to use.  Default is @samp{default}.

@item --begin_timestamp @var{BEGIN}
Specifies the TAXII collection to use.  Default is @samp{default}.

@item --end_timestamp @var{END}
Specifies the TAXII collection to use.  Default is @samp{default}.

@end table

The JSON information is written to the current directory to a file called
@file{stix-@var{COLLECTION}-combined.json} where @var{COLLECTION} is the
collection name chosen.

Begin/end timestamps take the following form:
@example
YYYY-MM-DDTHH:MM:SS.ssssss+/-hh:mm
@end example

@comment ----------------------------------------------------------------------

@node @command{taxii-server} invocation
@section @command{taxii-server} invocation

@cindex @command{taxii-server}, invocation

@command{taxii-server} provides a TAXII compliant
server to distribute cyber threat information.  TAXII/STIX implementation
is experimental and incomplete.

See
@url{https://taxii.mitre.org/} for more information on TAXII and STIX.
Synopsis:

@example
taxii-server [-h] [--host HOST] [--port PORT] [--data-dir DATA_DIR]
        [--db DB] [--sync-period SYNC_PERIOD]
@end example

Example:
@example
taxii-server --port 8100 --data-dir data/ --db stix.db
@end example

@table @samp

@item -h
@itemx --help
Shows command line usage.

@item --host @var{HOST}
Host to bind the HTTP service to.

@item --port @var{PORT}
Specifies port number of the TAXII service.

@item --data-dir @var{PATH}
Specifies the directory where STIX files are to be placed.  Directory
structure should be @var{PATH}/@var{COLLECTION}/@var{STIX-FILE}.

@item --db @var{DB}
Specifies a file to hold the STIX data.  Default is @file{stix_store.db}.
This is created if it does not exist.

@item --sync-period @var{PERIOD}
Specifies the period for synchronising the data directory with the database.
Default is @samp{1}.

@end table

The TAXII server periodically checks the data directory with the contents
of the database, and updates the database accordingly.  Deleting files results
in deletion from the database, adding files results in creation.  Thus, the
data directory is the master copy for the sync process.

@comment ----------------------------------------------------------------------

@node @command{nhis11-rcvr} invocation
@section @command{nhis11-rcvr} invocation

@cindex @command{nhis11-rcvr}, invocation

@command{nhis11-rcvr} provides a TCP server which accepts connections from
NHIS LI clients,  decodes NHIS LI streams and outputs contained IP  packets  on
the standard output in PCAP format.  TCP port number to use is provided
on the command line.  Synopsis:

@example
nhis11-rcvr @var{port-number}

@end example

@itemize @bullet

@item
@var{port-number} is the TCP port number to list to for connections.
See @ref{NHIS LI}.

@end itemize

@cindex @command{cyberprobe}, configuration

@command{nhis11-rcvr} executes indefinitely - to end the program, a signal
should be sent. e.g.

@example
killall nhis11-rcvr
@end example

@comment ----------------------------------------------------------------------

@node @command{etsi-rcvr} invocation
@section @command{etsi-rcvr} invocation

@cindex @command{etsi-rcvr}, invocation

@command{etsi-rcvr} provides a TCP server which accepts connections from
ETSI LI clients,  decodes ETSI LI streams and outputs contained IP  packets  on
the standard output in PCAP format.  TCP port number to use is provided
on the command line.  Synopsis:

@example
etsi-rcvr @var{port-number}
@end example

@itemize @bullet

@item
@var{port-number} is the TCP port number to list to for connections.
See @ref{ETSI LI}.

@end itemize

@cindex @command{cyberprobe}, configuration

@command{etsi-rcvr} executes indefinitely - to end the program, a signal
should be sent. e.g.

@example
killall etsi-rcvr
@end example

@comment ----------------------------------------------------------------------

@node ElasticSearch model
@section ElasticSearch model
@cindex ElasticSearch
@cindex ElasticSearch, model

@heading Overview

When @command{cybermon-elasticsearch} is used
observations are created in an ElasticSearch database.
These configuration files call the @file{elastic.lua} utility module.
This section describes the data model used in the ElasticSearch database.

ElasticSearch accepts data in JSON form.  @command{cybermon-elasticsearch}
uses an
index called @command{cyberprobe} and an object type @command{observation}.

Here is an example of a JSON payload which is emitted for a DNS request:
@example
@{
  "observation": @{
    "type": "query",
    "answers": @{@},
    "liid": "123456",
    "dest": @{
      "udp": ["53"],
      "dns": [""],
      "ipv4": ["192.168.1.1"]
    @},
    "queries": @{
      "name": ["news.bbc.co.uk"],
      "type": ["1"],
      "class": ["1"]
    @},
    "src": @{
      "udp": ["57291"],
      "dns": [""],
      "ipv4": ["192.168.1.100"]
    @},
    "time": "20141018T175059.366Z",
    "action": "dns_message",
    "id": 1
  @}
@}
@end example

@heading Common fields

The following fields are emitted for all observations:

@table @code

@item observation
This is a JSON object which describes a Cyberprobe observation.

@item observation.oid
A unique object ID.

@item observation.time
Describes the time of the event in GMT.  The components are:
@itemize
@item
4-digit year
@item
2-digit month
@item
2-digit date
@item
Literal @samp{T}.
@item
2-digit hour (24-hour).
@item
2-digit minute
@item
2-digit second
@item
Literal @samp{.}
@item
3-digit milliseconds
@item
Literal @samp{Z}
@end itemize
e.g. @code{20141018T175059.366Z}.
@item observation.liid
@cindex LIID
A string containing the targeted LIID.

@item observation.action
Describes the type of a Cyberprobe observation.  See @ref{Actions}
below.

@item observation.src
An object describing the full stack of protocol destination addresses.
For each name/value pair, the name is the protocol name, and the value
is an array of strings which are protocol addresses.  For example:
@example
"src": @{
  "udp": ["57291"],
  "dns": [""],
  "ipv4": ["192.168.1.100"]
@}
@end example

This specifies a UDP source port number of 57291, and an IP source address
of @code{192.168.1.100}.  Each protocol layer is list, allowing for more than
one address - protocol tunnels may result in more than IP address, for instance.

@item observation.dest
An object describing the full stack of protocol destination addresses, like
@code{observation.src} above, but for destination addresses.

@end table

@heading Actions
@anchor{Actions}
@cindex ElasticSearch model, actions
@cindex Actions

The following @code{action} fields are defined:

@table @samp
@item connected_up
Records the creation of a stream-orientated connection (currently, only TCP).
This event is created for all connections whether the protocol is
recognised or not.
@item connected_down
Records the closing of a stream-orientated connection (currently, only TCP).
This event is created for all connections whether the protocol is
recognised or not.
@item unrecognised_stream
Records the sending of a PDU on a connection-less transport (currently, only
UDP) whose protocol has not been recognised.
@item unrecognised_datagram
Records the sending of a PDU on a connection-less transport (currently, only
UDP) whose protocol has not been recognised.
@item http_request
Records the sending of an HTTP request.
@item http_response
Records the sending of an HTTP response.
@item dns_message
Records the sending of a DNS message (request and response).
@item icmp
Records the sending of an ICMP message.
@item smtp_command
Records the sending of an SMTP command.  This is a message from client
to server.  Data commands are not recorded with this event - there is an
@samp{smtp_data} event which records this.
@item smtp_response
Records the sending of a response to an SMTP command.  This is a status
message from server to client.
@item smtp_data
Records an SMTP data transaction, including the full SMTP data payload
(essentially an email).
@item ftp_command
Records an FTP command (client to server).
@item ftp_response
Records an FTP response (server to client).
@end table

@heading Connection up
@cindex Connection up

Connection up events are created when connection-orientated transports
(e.g. TCP) are created, and have an @code{action} field of @samp{connection_up}.

@heading Connection down
@cindex Connection down

Connection down events are created when connection-orientated transports
(e.g. TCP) are closed and have an @code{action} field of @samp{connection_down}.

@heading Unrecognised datagram
@cindex Unrecognised datagram

Unrecognised datagram events are created when a datagram is observed
on an unrecognised protocol, and have an @code{action} field of
@samp{unrecognised_datagram}.  Such events include the following fields:
@table @code 
@item observation.data
The datagram payload, base64 encoded.
@end table

@heading Unrecognised stream
@cindex Unrecognised stream

Unrecognised stream events are created when data is observed to be
sent on an unrecognised connection-orientated protocol (e.g. TCP),
and have an @code{action} field of
@samp{unrecognised_stream}.  Such events include the following fields:
@table @code 
@item observation.data
The datagram payload, base64 encoded.
@end table

@heading ICMP
@cindex ICMP

ICMP events are created when an ICMP message is observed
and have an @code{action} field of @samp{icmp}.  Such events include the
following fields:
@table @code 
@item observation.data
The datagram payload, base64 encoded.
@end table

@heading DNS messages

DNS events are created for DNS query and response messages, and have an
@code{action} field of @samp{dns_message}.  Such events include
the following fields:

@table @code 

@item observation.type
Used to describe the type of a DNS message, by interpreting the message flags.
Will be @samp{query} or @samp{response}.

@item observation.queries
Contains a list of DNS queries.  Example:
@example
"queries": [
 @{
    "class: "1",
    "name": "news.bbc.co.uk",
    "type": "1"
 @}
]
@end example

@item observation.answers
Contains a list of DNS responses.  Example:
@example
"answers": [
  @{
    "class: "1",
    "name": "newswww.bbc.net.uk",
    "type": "1"

  @},
  @{
    "class: "1",
    "address": "212.58.246.85",
    "name": "newswww.bbc.net.uk",
    "type": "1"
  @},
  @{
    "class: "1",
    "address": "212.58.246.84",
    "name": "newswww.bbc.net.uk",
    "type": "1"
  @}
]
@end example

@end table

@heading HTTP request
@cindex HTTP request

HTTP request events are created for HTTP requests, and have an
@code{action} field of @samp{http_request}.  Such events include fields:

@table @code

@item observation.method
The HTTP method e.g. @samp{GET}, @samp{POST}.

@item observation.url
The HTTP URL e.g. @samp{http://www.bbc.co.uk/index.html}.

@item observation.header
An object containing the request headers e.g.
@example
@{
  "Accept": "*\/*",
  "Referer": "http:\/\/www.bbc.co.uk\/news\/",
  "Accept-Language": "en-gb,en;q=0.5",
  "Host": "www.bbc.co.uk",
  "Accept-Encoding": "gzip, deflate",
  "Connection": "keep-alive",
  "User-Agent": "Test/5.0"
@}
@end example

@item observation.body
Describes the HTTP body.  This is a base64 encoding of the body.

@end table

@heading HTTP response
@cindex HTTP response

HTTP response events are created for responses to HTTP requests, and have an
@code{action} field of @samp{http_response}.  Such events include
the following fields:

@table @code

@item observation.code
The HTTP status code e.g. @samp{200}.

@item observation.status
The HTTP status response e.g. @samp{OK}.

@item observation.url
The HTTP URL e.g. @samp{http://www.bbc.co.uk/index.html}.  This is obtained
by studying the HTTP request, so will only be present where the HTTP
request is observed.

@item observation.header
An object containing the response headers e.g.
@example
@{
  "Server": "Apache",
  "Content-Type": "text/javascript"
@}
@end example

@item observation.body
Describes the HTTP response body, base64 encoded.

@end table

@heading SMTP command
@cindex SMTP command

SMTP commands events are created when an SMTP command is sent from client
to server, and have an @code{action} field of @samp{smtp_command}.
Such events include the
following fields:
@table @code 
@item observation.command
The SMTP command e.g. @samp{EHLO}.
@end table

@heading SMTP response
@cindex SMTP response

SMTP response events are created when an SMTP response is sent from server
to client, and have an @code{action} field of @samp{smtp_response}.
Such events include the following fields:

@table @code 
@item observation.status
The SMTP status e.g. @samp{400}.
@item observation.text
The SMTP text e.g. @samp{["Hello malware.com.  Pleased to meet you."]}.
@end table

@heading SMTP data
@cindex SMTP data

SMTP data events are created when an SMTP email is sent from client
to server, and have an @code{action} field of @samp{smtp_data}.
Such events include the following fields:

@table @code 
@item observation.from
The SMTP ``from'' address.  A string.
@item observation.to
The SMTP ``to'' addresses.  An array of strings.
@item observation.data
The SMTP payload (RFC822), base64 encoded.
@end table

@heading FTP command
@cindex FTP command

FTP commands events are created when an FTP command is sent from client
to server, and have an @code{action} field of @samp{ftp_command}.
Such events include the
following fields:
@table @code 
@item observation.command
The FTP command.
@end table

@heading FTP response
@cindex FTP response

FTP response events are created when an FTP response is sent from server
to client, and have an @code{action} field of @samp{ftp_response}.
Such events include the following fields:

@table @code 
@item observation.status
The FTP status.
@item observation.text
The FTP text.
@end table

@comment ----------------------------------------------------------------------

@node Architecture
@chapter Architecture
@cindex Cyberprobe, architecture
@cindex Architecture

@image{architecture,145mm,,png}

Cyberprobe consists of a set of loosely-coupled components which can be
used together. We prefer to use simple interfaces, and prefer to use
interfaces which are standards. Here's how we envisage these components
being used:

@table @code

@item cyberprobe
is a network sniffer which collects packets which match an IP address
list. The packets collected are streamed using network streaming
protocols. The IP address match list can be statically configured (in a
configuration file), can be dynamically changed using a management
interface, or can be dynamically changed as a result of Snort alerts.

@item cybermon
receives packets from cyberprobe, analyses them and generates
session/transport level events which result in user-configurable
actions. For each event, a call is made to a Lua script which the caller
provides.

@item cybermon-detector
@cindex @command{cybermon-detector} invocation
runs events past an IOC list, searching for
cyber threat indicators. When these indicators are observed, the indicator
meta-data is also added to the JSON events.

@item zeromq.lua
@cindex @file{amqp-topic.lua} configuration file
@cindex @code{cybermon}, @file{amqp-topic.lua} configuration file
is a cybermon configuration file we provide which publishes data to a
RabbitMQ pub/sub queue.  It allows connection of consumers to the
@command{cybermon} event stream.

@item cybermon-bigquery
@cindex @command{cybermon-bigquery}
@cindex Google BigQuery
@cindex BigQuery
is a RabbitMQ subscriber which output @command{cybermon} events to a
Google BigQuery table.

@item cybermon-cassandra
@cindex @command{cybermon-cassandra}
@cindex Cassandra
@cindex Apache Cassandra
is a RabbitMQ subscriber which output @command{cybermon} events to a
Cassandra store.

@item cybermon-elasticsearch
@cindex @command{cybermon-elasticsearch}
@cindex ElasticSearch
is a RabbitMQ subscriber which output @command{cybermon} events to a
ElasticSearch store.

@item cybermon-gaffer
@cindex @command{cybermon-gaffer}
@cindex Gaffer
is a RabbitMQ subscriber which output @command{cybermon} events to a
Gaffer store.

@item taxii-server
is a TAXII compliant server, which is used to distribute STIX rules over
HTTP.

@item taxii-client-json
is a TAXII compliant client, which fetches STIX data over TAXII and write it
to a JSON file in a way that @code{stix+db.lua} can read.

@item snort
is not part of cyberprobe, but it's a great NIDS, so we use that.

@end table

@comment ----------------------------------------------------------------------

@node GNU Free Documentation License
@appendix GNU Free Documentation License

@include fdl.texi

@node Index
@unnumbered Index

@printindex cp

@bye

